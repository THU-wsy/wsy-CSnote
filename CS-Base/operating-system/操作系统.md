
# 第1章 操作系统概述

## 1.1 操作系统的基本概念

### 操作系统的概念

操作系统是管理硬件资源、控制程序运行、改善人机界面和为应用软件提供支持的一种系统软件。

### 操作系统的目标和功能

- 操作系统是一个控制程序：它执行程序并给程序提供服务，控制程序执行过程防止错误，并且方便用户使用计算机系统
- 操作系统是一个资源管理程序：它是应用与硬件之间的中间层，管理各种软硬件资源，提供访问软硬件资源的服务，并且解决访问冲突，确保公平使用
- 操作系统作为用户与计算机硬件系统之间的接口：用户可以通过程序间接使用系统调用来请求操作系统为其提供服务。命令行接口(Shell)、图形用户接口(GUI)等。

### 操作系统的特征

并发：并发性是指计算机系统中同时存在多个运行的程序，这些程序宏观上是同时运行的，但微观上是交替运行的，因此操作系统具有处理和调度多个程序并发执行的能力。(注意与"并行"区分：并行指的是多个程序在同一时刻同时运行)。单核CPU同一时刻只能执行一个程序，所以各个程序只能并发地执行；多核CPU同一时刻可以同时执行多个程序，所以多个程序可以并行地执行。

共享：资源共享是指系统中的资源可供内存中多个并发执行的进程共同使用。
- 互斥共享方式：系统中的某些资源，虽然可供多个进程使用，但一个时间段内只允许一个进程访问该资源(我们把在一段时间内只允许一个进程访问的资源称为临界资源)
- 同时共享方式：系统中的某些资源，允许一个时间段内由多个进程"同时"对它们进行访问。这里的"同时"是指宏观上的，而在微观上这些进程可能是交替地对该资源进行访问的。

虚拟：虚拟是指把一个物理上的实体变为若干逻辑上的对应物。操作系统的虚拟技术可归纳为时分复用技术(如CPU虚拟化)和空分复用技术(如内存虚拟化)。

异步：异步是指在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进，这就是进程的异步性。

## 1.2 操作系统历史和结构

### 操作系统历史

单用户系统：手动纸带传输进行程序输入，此阶段无操作系统

批处理系统：磁带/磁盘传输进行程序输入，并由监督程序(操作系统的雏形)负责控制作业的输入/输出。优点是缓解了一定程度的人机速度矛盾；缺点是内存中仅能有一道程序运行，CPU有大量的时间是在空闲等待I/O完成，资源利用率依然很低。

多道程序系统：多个程序驻留在内存中，操作系统正式诞生，用于支持多道程序并发执行，资源利用率大幅提升。缺点是用户响应时间较长，不提供人机交互能力。

分时操作系统：计算机以时间片为单位轮流为各个作业服务。优点是用户请求可以被即时响应，用户可通过终端与计算机进行交互；缺点是不能优先处理一些紧急任务。

分布式系统：系统中的各台计算机地位相同，任何工作都可以分布在这些计算机上，由它们并行、协同完成这个任务。

个人计算机操作系统：如Windows、Linux等，方便个人使用。此外还有嵌入式操作系统、服务器操作系统、智能手机操作系统等。

### 操作系统结构

单体分层结构：将单体操作系统划分为多层，每层建立在低层之上，最底层是硬件驱动，最高层是用户界面，每一层仅使用更低一层的功能和服务。

微内核结构：尽可能把内核功能移到用户空间，只把最基本的功能保留在内核，用户模块间的通信使用消息传递。优点是灵活，缺点是性能低。

外核结构：让内核分配物理资源给多个应用程序, 并让每个程序决定如何处理这些资源，程序能链接到操作系统库 (libOS) 实现了操作系统抽象。

# 第2章 CPU虚拟化

## 2.1 进程

### 1. 进程的概念

定义：一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程称为进程(Process)，也称为任务(Task)。(而作业(Job)是指围绕一个共同目标由一组相互关联的进程形成的一个整体)

==程序是静态的==，是存放在磁盘里的可执行文件；而==进程是动态的==，是程序的一次执行过程，包含了运行程序的所有状态信息，同一个程序多次执行会对应多个进程。

进程的特点：
- 动态性
- 并发性：一段时间内多个进程在执行。
- 独立性：进程之间不用感知对方的存在。
- 异步性：由于进程的相互制约，使得进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应的进程同步机制。

### 2. 进程的组成

1. ==进程控制块PCB==
    PCB是操作系统管理进程的核心数据结构，它是进程存在的唯一标志，每个进程都有一个对应的PCB。Linux内核的PCB是task_struct结构体。PCB主要包括以下信息：
    - 进程描述信息：进程描述符PID(process identifier)，用pid_t类型表示，其实就是一个非负整数。用户id，组id等。
    - 进程状态信息：进程当前状态、进程优先级等
    - 占用资源信息：用于说明有关内存地址空间或虚拟地址空间的状况，所打开文件的列表和所使用的I/O设备信息等
    - 进程上下文：主要指CPU中各寄存器的值，用于进程切换

2. ==代码段==：代码段就是能被进程调度程序调度到CPU执行的程序代码段。注意程序可被多个进程共享，即多个进程可以运行同一个程序。
3. ==数据段==：一个进程的数据段，可以使进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。

注：PCB是给操作系统用的，而程序段、数据段是给进程自己用的，与进程自身的运行逻辑有关。例如同时挂着3个QQ号，会对应3个QQ进程，它们的PCB、数据段各不相同，但代码段的内容是相同的。

### 3. 进程状态

进程PCB中有一个变量来表示进程的当前状态。进程有三种基本状态：
- 运行态(running)：进程正在处理机上运行(单CPU下同一时刻只会有一个进程处于运行态)
- 就绪态(ready)：进程已准备好运行，但由于某种原因操作系统选择不在此时运行
- 阻塞态(blocked)：一个进程执行了某种操作(如向磁盘发起I/O请求)，直到发生其他事件时才会准备运行。又称为等待态(wait)或者睡眠态(sleep)。

除此之外，还会有另外两种状态：
- 初始态(initial)：进程正在被创建时处于的状态
- 最终态(final)：UNIX系统中称为僵尸态，是进程处于已退出但尚未清理的状态。这个状态非常有用，因为它允许其他进程(通常是父进程)检查进程的返回代码，并查看刚刚完成的进程是否成功执行


![](/zzimages/20230401000001.png)

![](/zzimages/20230401000002.png)

若系统有n个进程，则就绪队列中进程的个数最多有n-1个；阻塞队列中进程的个数最多有n个(死锁的情况)。

操作系统为了跟踪每个进程的状态，会为所有运行的、就绪的、阻塞的进程分别保留一种数据结构进程列表(process list)

![](/zzimages/20230401000001.png)

### 4. UNIX系统中的进程API

1. fork()系统调用
    系统调用fork()用于创建子进程(一个完全相同的进程，复制父进程的地址空间，只有PID以及fork()的返回值不同)。子进程不会从main()函数开始执行，而是直接从fork()系统调用返回后继续执行。==父进程的fork()返回值是新创建子进程的PID==，而子进程获得的返回值是0.

2. wait()系统调用
    父进程调用wait(NULL)进入阻塞状态，等待某个子进程结束，子进程结束时通过exit()向父进程返回一个值并唤醒父进程，将exit()返回值作为父进程中wait()的返回值。如果等待僵尸进程(即已经执行exit，但还没被父进程回收的子进程，注意与孤儿进程区分，孤儿进程是指其父进程先退出的子进程，一般孤儿进程由init进程负责回收)，则父进程调用wait()后立即返回其中一个值。若没有子进程，则wait()立即返回-1。
    进程结束执行时调用exit()，完成进程资源回收：将调用参数作为进程的结果，关闭所有打开文件等资源，释放内存和大部分进程相关的内核数据结构，检查父进程是否存活(若没有存活，则设置父进程为init进程)，然后进入僵尸状态，等待父进程回收。

3. exec()系统调用
    exec(argv\[0\], argv)会从可执行程序argv\[0\]中加载代码和静态数据，并用它覆写自己的代码段以及静态数据，堆、栈及其他内存空间也会被重新初始化，然后操作系统就执行该程序，将参数argv传递给该进程。因此，exec并没有创建新进程，而是直接将当前运行的程序替换为不同的运行程序，对exec()的成功调用永远不会返回。

常常结合fork和exec来运行一个程序：
```c
int pid = fork();
if (pid == 0) {
    //do something
    exec("program", argv);
}
```

### 5. 机制：受限直接执行

操作系统必须以高性能的方式虚拟化CPU，同时保持对系统的控制，为此采用了机制：==受限直接执行(limited direct execution, LDE)==，即让程序运行的大部分指令直接访问硬件，只在一些关键点(如进程发起系统调用或发生时钟中断)由操作系统介入。

#### 用户模式和内核模式

为了让一个进程能够执行一些受限制的操作，但又不能让进程完全控制系统，我们引入了用户模式(user mode)和内核模式(kernel mode)，用PSW的一个标志位来表示。用户模式下只能执行非特权指令(指允许用户直接使用的指令，它不能直接访问系统中的软硬件资源，仅限于访问用户的地址空间)，而内核模式下还可以执行一些特权指令(如I/O指令、置中断指令等)。

#### 系统调用

如果用户想执行某种特权操作，则可以通过系统调用。
- 系统调用是操作系统提供给应用程序(程序员)使用的接口，应用程序可以通过系统调用来请求获得操作系统内核的服务。
- 编程语言中使用的库函数，有些在底层包含系统调用(如open)，有些不包含系统调用(如abs)
- LDE协议过程：在系统引导时，内核初始化陷阱表(trap table)，并且CPU记住它的位置以供以后查询系统调用处理程序的位置；然后内核在设置一些内容后通过一条特权指令陷阱返回(return-from-trap)指令切换到用户模式运行进程。当进程希望发起系统调用时(通常通过一个称为陷阱(trap)的特殊硬件指令)，硬件将控制转移到预先指定的陷阱处理程序(trap handler, 即预先设置的操作系统)，并同时将特权级别提升到内核模式。执行陷阱时，处理器会将程序计数器、标志和其他一些寄存器推送到每个进程的内核栈(kernel stack)上。当操作系统完成请求的服务时，通过陷阱返回指令将控制权交还给用户，并从内核栈弹出这些数据，恢复执行用户模式程序。
- 可见trap指令是在用户模式下执行的，执行后引发内中断使CPU进入内核模式。发出系统调用请求是在用户模式下，而对系统调用的相应处理是在内核模式下进行。

#### 进程切换

当CPU运行其他进程时，操作系统失去了CPU的控制权，因此需要采取一些方式才能使操作系统重新获得CPU的控制权。早期采用协作方式，即操作系统等待系统调用或者某种非法操作发生，从而重新获得CPU控制权。现在一般采用非协作方式，利用==时钟中断==，时钟设备可以编程为每隔几毫秒产生一次中断，产生中断时当前正在运行的进程停止，从而操作系统中预先配置的中断处理程序会运行，操作系统重新获得CPU的控制权，然后决定是否切换进程(这个决定是由调度程序做出的)，如果决定切换，操作系统就会进行上下文切换(context switch)，即为当前正在执行的进程保存一些寄存器的值，并为即将执行的进程恢复一些寄存器的值。类似地，在系统引导时操作系统也必须启动时钟。

## 2.2 进程间通信

==进程间通信(IPC, Inter Process Communication)==是各进程之间通过数据交换(共享或传递)进行交互的行为。各进程拥有的地址空间相互独立，一个进程不能直接访问另一个进程的地址空间，但是我们又需要进程之间进行数据交换，所以操作系统提供了进程间通信方法。

## 2.3 处理机调度

处理机调度的基本概念：处理机调度就是从就绪队列中按照一定算法挑选下一个占用CPU运行的进程。如果是非抢占式系统，一般在当前进程主动放弃CPU时进行调度；如果是抢占式系统，一般还会在中断请求被服务例程响应完成时进行调度。

调度算法的评价指标：
- CPU利用率=CPU有效工作时间/(CPU有效工作时间+CPU空闲等待时间)
- 系统吞吐量：单位时间内CPU完成进程的数量
- 周转时间：指从进程到达系统到完成所经历的时间
    > 周转时间=进程完成时刻-进程到达时刻
    > 平均周转时间=各进程周转时间之和/进程数
    > 带权周转时间=进程周转时间/进程实际运行时间
    > 平均带权周转时间=各进程带权周转时间之和/进程数
    
- 等待时间：指进程处于等待处理机状态时间之和。(注意等待时间就是指进程建立后等待被服务的时间之和，而进程在等待I/O完成的期间也是在被服务的，所以不计入等待时间)
- 响应时间：指从进程到达系统到首次运行的时间。

调度算法：

### 先来先服务算法(FCFS, First Come First Served)

FCFS按照进程到达的先后顺序进行服务(即等待时间越长越优先)。

FCFS优点是公平，算法实现简单；缺点是会有护航效应，即一些耗时较少的进程可能排在较长进程之后。

### 短作业优先算法(SJF, Shortest Job First)

SJF要求执行时间最短的进程优先得到服务。

SJF优点是在所有作业同时到达的假设下，SJF是平均周转时间最少的算法；缺点是可能会导致饥饿(某进程长期得不到服务)，比如源源不断地有短进程到来，就可能使长进程长期得不到服务。

### 最短完成时间优先算法(STCF, Shortest Time-to-Completion First)

STCF是SJF算法的抢占式版本，每当有进程加入就绪队列时就需要调度，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则由新进程抢占处理机，当前运行进程重新回到就绪队列；另外，当一个进程完成时也需要调度。事实上几乎所有现代化的调度程序都是抢占式的。

STCF优点是它是==平均周转时间最少的算法==；缺点同样是可能导致饥饿。

### 最高响应比优先算法(HRRN，Highest Response Ratio Next)

HRRN综合考虑进程的等待时间和要求服务的时间，在每次调度时先计算各个进程的响应比，选择响应比最高的进程为其服务。它是非抢占式的算法。
==响应比=(等待时间+要求服务时间)/要求服务时间==

HRRN优点是综合考虑了等待时间和运行时间。等待时间相同时，要求服务时间短的优先(SJF的优点)；要求服务时间相同时，等待时间长的优先(FCFS)的优点。对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题；缺点是计算响应比的开销大。

注：FCFS、SJF、STCF和HRRN这四种算法并不关心响应时间，也不区分任务的紧急程度，所以对用户来说交互性很糟糕。这四种算法一般适合于早期的批处理系统，并不适合于交互式系统。当然FCFS算法也经常结合其他算法一起使用。接下来介绍的三种算法适合用于交互式系统。

### 时间片轮转算法(RR, Round-Robin)

主要适用于分时系统(所以更注重响应时间)，时间片轮转算法按照各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片(如100ms)，若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾。它是抢占式算法，由时钟装置发出时钟中断来通知CPU时间片已到，时间片长度必须是时钟中断周期的倍数。

优点是公平、响应快，适用于分时操作系统，不会导致饥饿；缺点是由于高频率的进程切换，因此有一定开销，且不区分任务的紧急程度。注意时间片的大小对系统的性能影响很大，如果时间片太大，会增大进程响应时间；如果时间片太小，会导致进程切换过于频繁，使处理机的开销增大，一般而言设计时间片时要让切换进程的开销占比不超过1%。可见，SJF和STCF优化周转时间，但对响应时间不利；而RR优化响应时间，但对周转时间不利。

### 比例份额调度算法(proportional-share)

有时也称公平份额调度(fair-share)，主要有两种实现方式：

1.彩票调度(lottery scheduling)：用一个进程的彩票数占总彩票数的百分比代表进程需要占用资源的份额。例如进程A拥有75张彩票，B拥有25张彩票，则在每个时间片都抽取彩票(用一个随机数发生器从0到99中随机选一个数)，如果抽到的数小于75就运行A，否则运行B(用一个列表串起A和B，A记录数量75，B记录数量25，用一个计数器从列表头开始不断累加彩票数，直到达到所选的随机数，就指向了中奖进程)。彩票调度还提供了一些其他机制来调度彩票：
- 彩票货币：允许拥有一组彩票的用户以其他类型货币将彩票分给自己的不同工作，之后操作系统再自动将这种货币兑换为统一的全局彩票。例如用户A和用户B每人各拥有100张彩票，用户A有两个进程，则可以分配给进程A1共400张A货币，分配给进程A2共600张A货币，用户B只有一个进程B1，选择分配给它10张B货币，于是操作系统进行兑换时，分别分配给A1、A2、B1各40、60、100张彩票。
- 彩票转让：一个进程可以临时将自己的彩票交给另一个进程。这种机制在客户端/服务端交互的场景中尤其有用，客户端可以将自己的彩票转让给服务端从而尽可能加速服务端执行自己请求的速度，服务端执行结束后会将这部分彩票归还给客户端。
- 彩票通胀：利用通胀，一个进程可以临时提升或降低自己拥有的彩票数量。通胀一般用于进程之间互相信任的环境，在这种情况下如果一个进程知道自己需要更多CPU时间就可以增加自己的彩票，这一切不需要与任何其他进程通信。

2.步长调度(stride scheduling)：系统中每个进程可以定义自己的步长，这个值与彩票数成反比，例如A、B、C各拥有100、50、250张彩票，则可以用10000除以彩票数得到A、B、C的步长分别为100、200、40。每次进程运行后，让该进程的计数器(称为行程值)增加对应步长，而当需要进程调度的时候，总是选择目前拥有最小行程值的进程。

彩票调度只能在一段时间后在概率上实现票数的比例，而步长调度可以在每个调度周期后做到完全正确；然而彩票调度的优势在于不需要全局状态，假如一个新的进程在步长调度执行过程中加入系统，设置其行程值就很麻烦(显然不能简单地设为0，否则它就会独占CPU很长时间)，但彩票调度则只需要用新进程的票数更新全局的总票数即可；事实上，比例份额调度并没有被广泛使用，一个原因是这两种方式都不能很好地适合I/O，更重要的原因是我们难以知道该为每个进程分配多少彩票数。

### 多级反馈队列算法(MLFQ, Multi-level Feedback Queue)

设置多级就绪队列，各级队列优先级从高到低，时间片从小到大，并按以下规则进行调度：
- 如果A的优先级大于B的优先级，则运行A
- 如果A的优先级等于B的优先级，则按FCFS原则的顺序轮转运行A和B
- 新进程到达时，放在最高优先级(最上层第1级)队列
- 一旦进程用完了其在某一层中的时间片(无论中间主动放弃了多少次CPU)，就降低其优先级，移入低一级队列队尾；若此时已在最下级队列，则重新放回该队列队尾
- 只有第k级队列为空时，才会为第k+1级队头的进程分配时间片
- 经过一段时间S，就将系统中所有进程重新加入最高优先级队列，从而防止饥饿。但S要合理设置，如果S太高则长进程会饥饿，如果S太低则交互型进程又得不到合适的CPU时间比例。

MLFQ有很多优点，对各类型进程相对公平(FCFS的优点)，每个新到达的进程都可以很快得到响应(RR的优点)，短进程只用较少的时间就可以完成(SJF的优点)，不必估计进程的运行时间(从而避免用户作假)，可灵活调整对各类进程的偏好程度(比如CPU密集型进程，I/O密集型进程，注意MLFQ将因I/O阻塞的进程重新放回原队列队尾，直到其一个时间片用完才会进入下一级队列)

![](/zzimages/20230401155321.png)

注意基于优先级的可抢占调度算法都会存在优先级反置问题，即出现高优先级进程长时间等待低优先级进程所占用资源的现象(例如优先级T1>T2>T3，而T3占用了T1所需的资源，于是T2就会长时间运行，从而阻碍T3释放资源，间接导致高优先级进程T1长时间等待)。一般有两种方法解决：一种是优先级继承，即占用资源的低优先级进程直接继承申请资源的高优先级进程的优先级；另一种是优先级天花板协议，即占用资源进程的优先级与所有可能申请该资源的进程的最高优先级相同。

## 2.4 实时调度和多处理机调度

### 实时调度

硬实时操作系统要求在指定的时间内必须完成重要的任务，软实时操作系统要求尽量在指定的时间内完成重要的任务。实时调度主要有：
- 速率单调调度算法：优先执行周期最短的实时任务
- 最早截止时间优先算法：优先执行截止时间最早的实时任务
- 最低松弛度优先算法：优先执行紧急度最高的任务

### 多处理器调度

多核处理器将多个CPU核组装在一块芯片上，产生的一个核心问题是Cache一致性问题，硬件提供的基本解决方案是监控内存访问(例如在基于总线的系统中，采用总线窥探的方式，即每个缓存都通过监听链接所有缓存和内存的总线来发现内存访问，从而保证Cache一致)。多处理器调度主要有以下两种方式：
- 单队列多处理器调度(SQMS, Single Queue Multiprocessor Scheduling)：复用单处理器调度的基本架构，将所有需要调度的进程放入一个队列中。优点是简单；缺点是缺乏可扩展性(需要在代码中加锁来保证原子性)，并且没有缓存亲和性(缓存亲和性是指尽可能让同一个进程在同一个CPU上运行)。
- 多队列多处理器调度(MQMS, Multi-Queue Multiprocessor Scheduling)：基本调度框架包含多个调度队列，每个队列可用不同的调度规则。可见每个CPU调度相互独立，避免了单队列方式的数据共享及同步问题，MQMS的优点是具有可扩展性和良好的缓存亲和性；缺点是会导致负载不均，一般采用将进程跨CPU迁移的方式来实现负载均衡(基本的方法是采用工作窃取，即进程量较少的队列不定期地偷看其他队列是不是比自己的进程多，如果更多的话就从其他队列中窃取一个或多个进程，实现负载均衡)。

### Linux多处理器调度

- O(n)调度：Linux最早采用的是O(n)调度，即调度时间与进程数量成正比的调度算法，该算法在每次分配时间片时都检查所有就绪进程的优先级，并选择优先级最高的的进程来执行一个时间片。该算法执行开销大，并且没有很好的可扩展性。
- O(1)调度：Linux发展中期采用过O(1)调度，它采用多队列，并用bitmap来记录优先级。
- CFS调度：Linux现在采用CFS调度(完全公平调度, Completely Fair Scheduler)，它也采用多队列，根据各个进程的优先级权重分配不同的运行时间，类似于步长调度的想法。
- BFS调度：BFS调度(Brain Fuck Scheduler)是时间片轮转算法的变种，采用单队列，基于比例调度，也称为最早最合适虚拟截止时间优先算法。

# 第3章 内存虚拟化

## 3.1 虚拟内存概述

### 1. 地址空间

一个进程的地址空间(address space)是一个物理内存的抽象，其中包含运行程序的所有内存状态，如程序的代码、栈(保存函数调用信息、分配空间给局部变量、传递参数和函数返回值等)、堆(管理用户动态分配的内存)、还有一些其他信息(如静态初始化的变量等)。地址空间是从虚拟地址0开始的，但操作系统将其加载到的实际物理地址是任意的，而运行的程序却总是认为自己被加载到地址0开始的内存中，并且占有非常大的空间，这正是操作系统在虚拟化内存。程序员可以看到的任何地址都是虚拟地址，只有操作系统和硬件才知道物理地址。

![](/zzimages/20230401155814.png)

### 2. 虚拟内存(VM)的目标

- 透明：操作系统实现虚拟内存的方式，不应该让进程感知到内存被虚拟化的事实，相反，进程的行为就好像它拥有自己的私有物理内存。在幕后操作系统和硬件完成了所有的工作，让不同的进程复用内存，从而实现这个假象。
- 效率：操作系统应该追求虚拟化尽可能在时间上和空间上高效。
- 保护：操作系统应确保进程受到保护，不会受其他进程影响。当一个进程执行加载、存储或指令提取时，它不应该以任何方式访问或影响其他进程或操作系统本身的内存内容(即在它的地址空间之外的任何内容)。

### 3. 内存操作API

运行一个C程序时会分配两种类型内存：

第一种是==栈内存==，它的申请和释放操作是==编译器隐式管理==的，所以有时也称为自动内存
```c
void func() {
    int x; //在栈上声明一个int
}
```

第二种是==堆内存==，其中所有的申请和释放操作都由==程序员显式完成==

```c
void func() {
    int* p = (int*)malloc(100 * sizeof(int));
}
```
上述代码在堆上请求100个int大小的空间，返回一个地址，这个地址存储在栈上。

malloc()：参数是要申请的堆空间大小(字节)，一般利用sizeof更简便，返回类型是void\*，若成功就返回一个指向新申请空间的指针，失败则返回NULL，一般使用强制类型转换来得到指向某个数据类型的指针。如果为一个字符串申请堆空间，一般使用malloc(strlen(s)+1)

free()：接受一个由malloc()返回的指针作为参数，释放空间

动态内存分配时常见的错误：
- 段错误(segmentation fault)：发生非法的内存访问
    ```c
    char src[] = {'a','b','c','\0'};
    char* dst; 
    strcpy(dst, src); //没有给dst分配内存导致段错误，应将其改为：
    char* dst = (char*)malloc(strlen(src) + 1);
    ```
- 缓冲区溢出(buffer overflow)：没有分配足够的内存就可能导致缓冲区溢出
- 忘记初始化分配的内存就进行读取，可能会读到一些未知值的数据
- 内存泄漏(memory leak)：如果忘记释放内存，就会让内存缓慢泄露导致内存不足
- 悬挂指针(dangling pointer)：释放内存即对指针进行free之后还对它进行读取等操作就会出现错误。对指针进行free后应将其设置为NULL，以防成为悬挂指针(指向已回收的内存地址的指针)，注意与野指针区分(野指针是未初始化的指针)。
- 重复释放内存
- 错误调用free()：即对free的参数传入一些其他的值

注1：事实上我们的短进程退出时，即使之前没有释放内存，也不会导致内存泄漏。这是因为系统中实际存在两级内存管理：第一级是由操作系统执行的内存管理，它在进程运行时将内存交给进程，并在进程退出时将其回收；第二级管理在每个进程中，比如调用malloc()和free()时在堆内管理。因此即使你没有调用free()回收内存，操作系统也会在程序结束运行时收回进程的所有内存。但我们仍应该养成主动释放内存的好习惯，因为对于长进程来说不释放内存很可能导致内存泄漏。

注2：==malloc和free都是库调用==，但它们是建立在一些系统调用之上的(比如系统调用brk用来改变堆结束的位置，sbrk要求传入一个增量等等)

注3：我们还可以通过mmap()调用从操作系统获取内存，它在程序中创建一个匿名内存区域，这个区域不与任何特定文件相关联，而是与交换空间相关联；calloc()分配内存并全部初始化为0；realloc()创建一个新的更大的内存区域，将旧区域复制到其中并返回新区域的指针，例如可以用于想对一个数组添加元素的时候。

## 3.2 动态重定位

### 1. 地址转换

硬件对每次内存访问进行处理，将指令中的虚拟地址转换为数据实际存储的物理地址，这一过程称为地址转换。(逻辑地址和虚拟地址类似，区别在于逻辑地址指CPU在段式内存管理转换前的地址，而虚拟地址指CPU在页式内存管理转换前的地址)

### 2. 静态重定位

早期系统采用纯软件的静态重定位方式，一个名为加载程序的软件接手将要运行的可执行程序，将它的地址重写到物理内存中期望的偏移位置。例如，一条指令中含地址1000，如果整个程序的地址空间被加载到从3000开始的物理地址中，那么加载程序会将该指令中的地址1000重写为4000，从而完成静态重定位。这种方式既缺少访问保护，又难以在运行时在内存中移动位置。

### 3. 动态重定位

动态重定位，又称基址加界限机制，通过每个CPU芯片上的一对基址寄存器和界限寄存器，来实现地址转换，CPU的这个负责地址转换的部分统称为内存管理单元(Memory Management Unit, MMU).

- 进程中使用的内存引用都是虚拟地址，硬件接下来先用界限寄存器(界限寄存器中保存该进程地址空间的大小)确保这个虚拟地址没有越界，然后将虚拟地址加上基址寄存器中的内容，得到物理地址再发给内存系统。
- 例如执行指令128: movl 0x0(%ebx), %eax的过程如下：假设%ebx中保存的值是15KB，基址寄存器中的值是32KB，界限寄存器中的值是16KB，则首先程序计数器被设置为128，硬件需要先获取这条指令，比较128小于界限寄存器中的值16KB，于是将虚拟地址128加上32KB得到指令的物理地址为32896，然后硬件从这个物理地址获取指令；接下来处理器开始执行该指令，进程要读取虚拟地址15KB处的值，比较15KB小于界限寄存器中的值16KB，于是将虚拟地址15KB加上32KB得到物理地址47KB，从而获取所需数据。
- 动态重定位是在==运行时==发生的，并且可以在进程开始运行后改变其地址空间；但是这个简单的动态重定位技术有效率低下的问题，比如栈区和堆区很小时，导致这块内存区域中大量空间被浪费，这种浪费称为==内部碎片，指的是已经分配的内存单元内部有未使用的空间而造成浪费==。

## 3.3 内存分配

内存分配方式有静态内存分配和动态内存分配：静态内存分配是指编译时的内存分配，包括全局、静态变量和代码，它们位于全局/静态数据段、常量数据段、代码段；动态内存分配是指运行时的内存分配，如堆、栈的分配(==栈是一块连续的较小内存，编译期间确定大小，而堆是一个较大的不连续存储空间==)，动态内存分配又分为连续内存分配(以下将讨论的动态分区分配，其核心是空闲空间管理)和非连续内存分配(分段、分页)。

如果要管理的空闲空间是由大小相同的单元构成的(如分页)，那么管理就很容易。但如果大小不同，如用户级的内存分配(malloc和free)或是用分段实现的虚拟内存系统，都容易出现外部碎片，所以需要采取适当的空闲空间管理策略来尽可能减少外部碎片。

### 1. 底层机制

采用空闲列表(free list)的数据结构，记录了空闲的空间。需要分配空间时，通过空闲列表找到一块大小可以满足请求的空闲空间，将其分割，第一块返回给用户，第二块留在空闲列表中。需要释放空间时，会查看要归还的内存块的地址以及邻近的空闲空间块，如果相邻就会进行合并。

每个已分配空间会有一个头块(header)，用于包含所分配空间大小、额外的指针用于加速空间释放、一个幻数用以提供完整性检查等其他信息。所以调用free时只需提供一个指向头块的指针即可，它会首先确定幻数是否符合预期值作为正常性检查，然后自动计算要释放的空间大小(头块大小加上所分配空间大小)。==注意如果是请求N字节的内存，实际上是寻找N加上头块大小的空闲块==。

空闲块也需要加上一个头块，其中需要指针指向下一块空闲块，从而形成了空闲列表。

### 2. 分配空间的基本策略

最优匹配(best fit)：遍历整个空闲列表，找到满足请求大小的最小的空闲块。这种算法性能通常很差，因为每次最优分配会留下很小的难以利用的内存块，会产生最多的外部碎片。

最差匹配(worst fit)：遍历整个空闲列表，找到满足请求大小的最大的空闲块。这种算法把最大的连续内存划分开，会很快导致没有可用的大内存块，因此性能也非常差。

首次匹配(first fit)：从列表头开始找到第一个满足请求大小的空闲块。管理空闲列表的顺序一般基于地址排序，从而使得合并操作更容易。这种算法最简单，一般也是最好的，但缺点是内存的低地址部分会出现很多小的空闲分区。

下次匹配(next fit)：从上一次查找结束的位置开始继续找到第一个满足请求大小的空闲块。该算法可能导致各大分区均被使用，最后导致无大分区可用，所以通常比首次匹配算法要差。

### 3. 其他方式

分离空闲列表：如果某一个应用经常申请一种大小的内存空间，就用一个独立的列表只管理这样大小的对象，其他大小的请求都交给通用的内存分配程序。

二分伙伴分配程序：空闲空间被视作大小为$2^N$的大空间。当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小。例如一个64KB的空闲空间，当有一个7KB的分配请求时，它就会被分成8KB，8KB，16KB，32KB，然后将最左边的8KB块分配给用户。显然由于空闲块都是2的幂次大小，所以会有内部碎片，然而这一策略的优势之处在于合并，在将这个8KB的块归还时，会先检查他的另一个8KB的伙伴是否空闲，如果空闲就合二为一，一直递归合并，直到某一个块的伙伴还没有被释放或者合并整个内存区域，其中核心在于很容易确定一个块的伙伴，因为每对互为伙伴的块的地址只有一位不同。

## 3.4 分段

### 1. 分段的概念

由于通过简单的基址寄存器和界限寄存器实现虚拟内存会产生很多内部碎片，并且如果剩余物理内存无法提供连续区域来放置完整的地址空间，就会导致进程无法运行，因此我们引入了分段的技巧：==在MMU中给地址空间内的每个逻辑段都分配一对基址寄存器和界限寄存器==。一个段只是地址空间里的一个连续的区域(长度可以不同)，在典型的地址空间里可以分成3个逻辑不同的段：代码、栈和堆。分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中的未使用部分占用物理内存。

### 2. 分段的具体实现

![](/zzimages/20230401161102.png)

![](/zzimages/20230401161111.png)

### 3. 分段的其他特点

==分段容易实现信息的共享和保护==，只需要为每个段添加保护位，就可以实现内存共享。例如一个只读的代码段可以被多个进程共享，虽然每个进程都认为自己独占了这块内存，但操作系统秘密地共享了这块内存。注意设置了保护位后，硬件除了要检查虚拟地址是否越界，还要检查特定访问是否允许。分段比分页更容易实现信息共享和保护，因为一个页面内可能只有一部分允许被其他进程访问。

我们称上述只有很少的几个段的系统(即代码、栈、堆)为粗粒度的分段。一些早期系统允许将地址空间划分为大量较小的段，这被称为细粒度的分段，这种分段需要进一步的硬件支持，并==在内存中保存某种段表==(段表与上述段寄存器类似，用来记录各段在物理内存中的基址和大小)。

分段的方法确实能大量节省物理内存，然而由于每个进程的段大小可能不同，因此物理内存很快会充满许多空闲空间的小洞，从而导致==外部碎片(即内存中的某些空闲空间由于太小而难以利用==，比如新的段需要的内存大小比这些空闲空间累加起来的大小要小，但却比任意单独空闲空间的大小要大，从而导致这个段无法分配内存)。该问题的一个解决方案是紧凑(compact)物理内存，即重新安排原有的段，但成本很高；另一种更简单的做法是利用空闲列表管理算法，试图保留大的内存块用于分配，但无论各种算法多么精妙都无法完全消除外部碎片。

事实上分段还是不足以支持更一般化的稀疏地址空间(包含大量未使用的地址空间)，比如有一个很大但是稀疏的堆，都在一个逻辑段中，整个堆仍然必须完整地加载到内存中。

## 3.5 分页

### 1. 基本概念

将进程的虚拟地址空间和物理内存都划分为大小相同的单元，分别称为页面(page)和页帧(page frame)。操作系统为每个进程保存一个称为页表(page table)的数据结构，用以记录地址空间的每个虚拟页号所对应的物理页号。例如一个64B的虚拟地址空间，设页面大小为16B，则在6位的地址中，后4位作为页内偏移量(offset)，前2位则为虚拟页面号(virtual page number, VPN)，当进程生成某个虚拟地址时，检索页表查找VPN所对应的物理帧号(physical frame number, PFN, 有时也称为物理页号, physical page number, PPN)，然后用PFN替换VPN就得到了物理地址(注意offset是保持不变的)。

### 2. 页表

最简单的形式就是线性页表(即一个数组)，操作系统通过虚拟页号VPN检索该数组，并在该索引处查找页表项PTE以便找到期望的物理帧号PFN。每个PTE的内容除了PFN外(注意VPN是隐含的，并不属于页表项的内容)还有许多不同的位：
- 有效位(valid bit)：用于指示该虚拟页是否被进程申请使用。无效的虚拟页被访问时会陷入操作系统，然后杀死该进程。
- 保护位(protection bit)：表明页是否可以读取、写入、执行等。
- 存在位(present bit)：表明该页是在物理内存中还是在磁盘上。
- 脏位(dirty bit)：表明页面被带入内存后是否被修改过。
- 引用位(reference bit，也称访问位，accessed bit)：用于页面替换算法。

分页的优点是不会导致外部碎片，并且十分灵活，支持稀疏虚拟地址空间。

每个进程的页表一般都存储在内存中，但我们经过简单的计算会发现页表占用的内存非常大。比如一个典型的32位地址空间，带有4KB的页，于是虚拟地址被分为20位的VPN和12位的offset，所以它的页表需要1M个页表项，假设每个PTE占用4个字节，则该页表就占用了4MB内存，如果100个进程同时运行，仅仅页表就会占用400MB内存。因此我们需要一些方法来克服页表占用太多内存的问题。

硬件用页表基址寄存器(包含页表的起始位置的物理地址)来找到正在运行的进程的页表位置，用页表界限寄存器(保存页表项的数量)来判断是否越界。因此，对于每个内存引用，都需要先访问一次内存查找页表，然后通过页表转换成物理地址后再访问内存。两次访存会导致系统运行速度过慢，这也是需要改进的问题。

### 3. 快速地址转换

为了解决访问页表速度太慢的问题，我们增加了地址转换旁路缓冲存储器(translation-lookaside buffer, TLB)，它就是频繁发生的虚拟地址到物理地址转换的硬件缓存(所以更好的名称应该是地址转换缓存)。硬件算法流程如下：首先从虚拟地址中提取页号VPN，然后检查TLB是否拥有该VPN的转换映射，如果有则TLB命中，于是从该TLB项中取出页帧号PFN，与原来虚拟地址中的offset组成物理地址PA，然后访存；如果TLB未命中，则硬件或操作系统访问页表来寻找转换映射，并用该转换映射更新TLB，然后重新尝试该指令，这时TLB中有了这个转换映射，内存引用得到很快处理。

- 当TLB未命中时，以前的CISC让硬件来处理，即硬件知道页表在内存中的位置，然后遍历页表找到正确的页表项并更新TLB，然后重试该指令；更现代的RISC让软件处理，即当TLB未命中时硬件会抛出一个异常，然后陷入操作系统，跳转至未命中处理程序，让操作系统来查找页表并更新TLB，从陷阱返回后硬件会重试该指令。
- 典型的TLB有32项、64项或128项，并且是全相联的(fully associative)。一条TLB项至少包含VPN，PFN和其他位，比如有效位(TLB项的有效位是指该TLB项是不是有效的地址映射，与页表项的有效位含义不同)、保护位、地址空间标识符、脏位等。
- 上下文切换时对TLB的处理：在进程间切换时，TLB中包含的地址映射只对当前进程有效，对其他进程是无意义的(所以可能在TLB中会有两项将同一个虚拟地址映射到不同物理地址，本质上是因为这是两个不同进程的虚拟地址，所以我们必须采取一些方法处理这种情况)。一种方法是当进程切换时，直接将所有有效位置0，本质上清空了TLB，但每次进程切换后都会触发TLB未命中，开销很大；另一种方法是利用TLB项中的地址空间标识符(Address Space Identifier, ASID)，它可以看做是进程标识符(Process Identifier, PID)，但通常比PID位数少，所以在上下文切换时，操作系统只需将某个特权寄存器设置为当前进程的ASID，然后查询TLB时就能区分是否是当前进程的地址映射了。

### 4. 多级页表

为了解决页表占用太大内存的问题，我们需要采取一些方法。一种方法是使用更大的页，但这样会导致更多的内部碎片；另一种方法是杂合使用分段和分页，即不是为每个进程的整个地址空间提供单个页表，而是为每个进程的每个逻辑分段提供一个页表，比如我们可以将地址空间分为代码段、堆段和栈段，因此需要3个页表(同样需要3对基址寄存器和界限寄存器，只不过基址寄存器用来存放该段页表的地址，而界限寄存器保存该段页表项的数量)，例如32位虚拟地址空间包含4KB页面，则使用前2位来保存段号，后12位保存offset，中间18位则为VPN，但这种方式的缺点仍像分段一样不够灵活，并且导致外部碎片，尽管大部分内存是以页面大小单位管理的，但页表大小可以是任意的(PTE的倍数)，因此在内存中为它们寻找自由空间更为复杂；许多现代操作系统用的更多的是多级页表的方法。

- 多级页表的思想：将页表分成页大小的单元，如果其中某整页的页表项都无效，就完全不分配该页的页表，为了追踪页表的页是否有效(以及如果有效，它在内存中的位置)，使用了名为页目录的新结构。例如一个简单的两级页表，页目录为每页页表包含了一个页目录项(Page Directory Entries, PDE)，PDE至少拥有页帧号(下一级页表所在的物理页帧号)和有效位(有效是指该项指向的一页页表中至少有一个页表项是有效的，无效是指该项的页帧号部分没有定义，比如这一项本该指向某一页页表，但该页表中所有页表项都无效，所以实际上在内存中并不分配该页页表，因此只需简单地将该PDE有效位置0即可)
- 多级页表一个显然的优势是可以节省空间，因为如果一级页表中的一个PTE是无效的，那么相应的二级页表根本就不会存在；除此之外，页表的每个部分都可以整齐地放入一页中，从而更容易管理内存(每页页表之间无需连续存放)，假如我们有一个30位的地址空间，页面大小为512B，每个PTE为4字节，那么地址低9位是offset，高21位是VPN，由于每页可以存放128个PTE，所以每页页表需要7位索引，于是从VPN低位开始每7位划分，分别是三级索引、二级索引、一级索引；注意只有一级页表需要总是在主存中，而二级页表可以换入换出，从而同样节省了内存空间。但多级页表是有成本的，在TLB未命中时，需要根据索引多次访存才能得到信息。
- 注意在任何复杂的多级页表访问发生前，硬件都首先检查TLB，在命中时物理地址直接形成，只有在不命中时才要执行完整的多级查找。
- 一个更极端的空间节省方法是反向页表，它在系统中只保留了一个页表，其中的页表项代表系统的每个物理页，告诉我们哪个进程正在使用此页以及该进程的哪个虚拟页映射到此物理页(所以反向页表更适用于虚拟地址空间很大的时候，因为反向页表的大小只与物理内存大小有关，而与地址空间大小无关)。每当要找一个虚拟页就必须扫描整个反向页表，因此通常用散列表来加速查找，即将虚拟地址先作散列映射以减少搜索范围，然后需要解决可能的冲突(一般也会通过快表来缓存该反向页表，即对虚拟地址作散列映射后现在快表中查找对应页表项，有冲突时遍历冲突项链表，查找失败时产生异常)。

### 5. 按需分页

由于多道程序和易用性(便于程序员编程，无需考虑内存大小)都需要操作系统支持比物理内存更大的地址空间，所以我们需要在硬盘上开辟一部分空间用于物理页的移入和移出，称为交换空间(swap space)。判断虚拟页是否在内存中的方法，是利用页表项中的存在位，如果存在位是1，则表示该页存在于物理内存中，如果存在位是0，则表示该页在硬盘上，此时用PTE中的PFN的位来表示该页的硬盘地址。注意交换空间并不是唯一的硬盘交换的目的地，比如可执行二进制文件的代码页以及动态加载的共享库程序段，就是在硬盘的文件区，而不是交换空间，该页如果被内存踢出，再使用的时候也只需从储存该代码的文件区加载即可。(像堆栈段一般放在交换空间)

- 访问不在物理内存中的页，这种行为称为页错误(page fault)或页未命中(缺页，page miss)。假设访问一个虚拟地址后，TLB未命中，然后访问页表，如果发生页错误，就会陷入操作系统的页错误处理程序，操作系统根据硬盘地址向硬盘发送请求将页读取到内存中，当硬盘I/O完成时，操作系统会更新页表(存在位置1，更新PFN字段记录页在物理内存中的位置)，并重试该指令，此时仍会TLB未命中，但是读页表时不会发生页错误，于是把地址更新到TLB中(也可以在处理页错误时就更新TLB以避免此步骤)，接下来再重试该指令，TLB命中。
- 注意，当上述I/O运行时进程将处于阻塞状态，所以此时可以自由运行其他可执行进程
- 如果内存接近满了，则需要根据替换算法选择换出一些页。具体来说，操作系统会预留一小部分空闲内存，操作系统会设置高水位线(High Watermark, HW)和低水位线(Low Watermark, LW)来帮助决定何时从内存中清除页。原理如下：当操作系统发现有少于LW个页可用时，后台负责释放内存的线程(交换守护进程，swap daemon)会开始运行，直到有HW个可用的物理页，之后操作系统就可以正常发出I/O请求从交换空间读取页了。注意，许多系统会把多个要写入的页聚集(cluster)或分组(group)，同时写入到交换空间，从而提高硬盘的效率(减少了硬盘的寻道和旋转开销)。
- 早期也采用覆盖技术：程序员把一个程序划分为一系列功能相对独立的程序段，让执行时不要求同时装入内存的程序段组成一组（称为覆盖段），共享主存的同一个区域。即将常用的代码和数据常驻内存，而不常用的只在需要时装入内存，不存在调用关系的模块可相互覆盖，共享同一块内存区域。覆盖技术的明显缺陷是编程困难，并且执行时间长。

### 6. 替换策略

最优替换策略(OPT, optimal)：替换内存中在最远将来才会被访问到的页。该算法未命中率最低，然而未来的访问是操作系统无法预知的，所以只能作为一个完美标杆，让其他策略尽可能接近它。

先入先出替换策略(FIFO)：页在进入系统时简单地放入一个队列，根据FIFO原则替换。这一算法实现简单，但是根本无法确定页的重要性，甚至会产生Belady异常(一般来说当缓存变大时，缓存命中率会提高，但是FIFO反而可能导致命中率下降，这种现象称为Belady异常)。

随机替换策略：随机替换。同样实现简单，但无法确定页的重要性。

最不经常使用替换策略(Least-Frequently-Used, LFU)：每次替换使用次数最少的页面。该算法并没有很好遵循局部性原理，性能不如LRU。

最近最少使用替换策略(Least-Recently-Used, LRU)：每次替换的页面是最近最久未使用的页面。LRU实现较为困难，比如硬件在每个页访问时更新内存中的时间字段，即页被访问时页表项中的时间字段被硬件设置为当前时间，于是在需要替换页时扫描系统中所有页的时间字段以找到最近至少使用的页，然而这种方法代价比较昂贵。

近似LRU：==每当页被访问时，硬件将页表项中对应的引用位置1==，用==时钟算法==来实现近似LRU。即，内存中的所有页都放在一个循环列表中，时钟指针开始时指向某个页，当必须进行页替换时，操作系统检查当前指向的页P的引用位，如果是0则进行替换(然后时钟指针递增)，如果是1，则将其置0，然后时钟指针递增到下一页(P+1)，直到找到引用位是0的页面为止。时钟算法也有一个变种，即进行页替换时随机扫描各页，如果引用位为1就置0，直到找到一个引用位为0的页进行替换。
注1：时钟算法的一个小改进是优先替换脏位为0(即未被修改过)的未引用页(这样无需写回磁盘)，如果找不到的话再找脏位为1的未引用页。
注2：如果刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出内存，这种频繁的页面调度行为称为抖动，产生抖动的的主要原因是进程频繁访问的页面数高于可用的物理页数。例如循环访问从0到4号页，而内存大小只有4页，则FIFO和LRU都产生了抖动导致命中率为0。早期系统会采用准入控制的方法减少抖动，即不运行部分进程，让剩余进程工作集能放入内存；现代系统如Linux会运行内存不足的杀手程序，选择一个内存密集型进程直接杀死它，从而以不委婉的方式减少内存。(一个进程的驻留集是指给它分配的物理页的集合，工作集是指在一段时间内它实际访问的物理页的集合，一般驻留集大小不能小于工作集大小，否则进程运行过程中将频繁换页产生抖动)
注3：缓存未命中有三类：强制性未命中(或冷启动未命中，是因为缓存开始是空的，而这是对项目的第一次引用)，容量未命中(由于缓存的空间不足而不得不踢出一个项目以将新项目引入缓存)，冲突未命中(出现在硬件中，因为硬件缓存中对项的放置位置有限制，比如采用直接映射的方式，就会产生冲突未命中，而全相联映射则不会发生冲突未命中，所以操作系统页面缓存不会发生冲突未命中)

### 7. 其他虚拟内存技巧

访问空指针会导致段错误，因为0号虚拟页被标记为无效。

按需置零(demand zeroing)：当页添加到你的地址空间时，操作系统只会在页表中放入一个标记页不可访问的条目，如果进程访问该页，则会陷入操作系统，并且注意到这实际上是一个按需置零页(通常通过页表项中"保留的操作系统字段"部分标记的一些位)，此时操作系统才会完成寻找物理页的必要工作并将它置零，然后映射到进程的地址空间。按需置零的好处是如果进程从不访问该页，就可以免去做这些工作的开销。

写时复制(copy-on-write, COW)：如果操作系统需要将一个地址空间的某个虚拟页所对应的物理页复制到另一个地址空间，则并不会实际复制它，而是将该物理页映射到目标地址空间，并在两个地址空间中将其标记为只读。如果两个地址空间都只读取页面，则不会采取进一步操作，于是操作系统就实现了快速复制而不实际移动任何数据。但是如果其中一个地址空间尝试写入页面，就会陷入操作系统，操作系统注意到这是一个COW页面，于是惰性地分配一个新物理页填充数据，并将这个新物理页映射到错误处理的地址空间，该进程然后继续，现在有了该页的私人副本。

# 第4章 并发

## 4.1 线程

### 1. 线程(Thread)

在网络或多用户换机下，一个服务器通常需要接收大量不确定数量用户的并发请求，为每一个请求都创建一个进程显然行不通(系统开销大响应用户请求效率低)，因此操作系统中线程概念被引进。线程是进程中的一个执行任务，是一个基本的CPU执行单元，==也是程序执行流的最小单元==，负责当前进程中程序的执行。一个进程中可以同时存在多个线程。

- 一个进程的多个线程共享该进程的地址空间。==线程共享本进程中一些资源(如初始化数据段、未初始化数据段、堆内存段等)，但每个线程有自己的寄存器、程序计数器和栈，因此该进程的地址空间里会有多个栈。==同一进程的线程间进行上下文切换时地址空间保持不变，只需要切换线程的栈、寄存器等不共享的数据，所以系统开销小，因此线程也被称为轻量级进程(LWP：Light Weight Process)。传统意义上的UNIX进程只是多线程程序的一个特例(即该进程只包含一个线程)，因此Linux环境下线程的本质仍是进程。在Linux下可以用命令ps -Lf pid来查看进程pid的所有LWP号。
- ==进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。==
- 每个线程都有一个线程ID、线程控制块(TCB)；线程也有就绪、阻塞和运行三种基本状态；线程几乎不拥有系统资源；多CPU计算机中，各个线程可占用不同的CPU并行运行，提升效率。
- 不同的线程可以执行相同的程序，即同一个服务程序被不同用户调用时，操作系统把它们创建成不同的线程
- 进程间的信息难以共享，必须采用一些进程间通信方式，且调用fork()创建进程的代价相对较高，因为需要复制页表、文件描述符表等多种进程属性；而创建线程通常比创建进程要快10倍甚至更多，因为线程间共享虚拟地址空间，无需复制页表等属性，并且线程间能方便快速地共享信息，只需将数据复制到共享(全局或堆)变量中即可。

==同一进程的线程之间的共享资源==：
- 进程ID和父进程ID；进程组ID和会话ID；用户ID和用户组ID
- 文件描述符表
- 信号处置(即注册的信号处理函数)
- 文件系统的相关信息：如文件权限掩码umask、当前工作目录等
- 虚拟地址空间(除栈、.text)

==非共享资源==：
- 线程ID、一些线程特有数据
- 信号掩码(即阻塞信号集)
- error变量
- 实时调度策略和优先级
- 栈(一般系统默认为每个线程分配8MB的栈空间)，本地变量和函数的调用链接信息

### 2. 一些并发术语

- 临界资源：一个时间段内只允许一个进程使用的资源称为临界资源，对临界资源的访问必须互斥地进行
- 临界区：线程中访问临界资源的那段代码
- 竞态条件：出现在多个执行线程大致同时进入临界区时，它们都试图更新共享的数据结构，导致了令人惊讶的结果。
- 不确定性：不确定性程序由一个或多个竞态条件组成，程序的输出因运行而异
- 互斥：指当一个线程进入临界区使用临界资源时，另一个线程必须等待，当占用临界资源的线程退出临界区后，另一线程才允许去访问此临界资源。
- 同步：指为完成某种任务而建立的两个或多个线程，这些线程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。
- 原子性：能够一气呵成执行(不可被中断)的代码称为具有原子性
- 临界区应遵循以下访问规则：
    > 空闲则入：没有线程在临界区时，任何线程可进入
    > 忙则等待：有线程在临界区时，其他线程均不能进入临界区
    > 有限等待：等待进入临界区的线程不能无限期等待
    > 让权等待（可选）：不能进入临界区的线程，应释放CPU（如转换到阻塞状态）
    
### 3. 线程API

#### 锁

```c
int pthread_mutex_lock(pthread_mutex_t* mutex);
int pthread_mutex_unlock(pthread_mutex_t* mutex);
```
通过锁使得线程互斥进入临界区，例如：
```c
pthread_mutex_t lock;
pthread_mutex_lock(&lock);
x = x + 1; //critical section
pthread_mutex_unlock(&lock);
```
这段代码的意思是：如果在调用pthread_mutex_lock时没有其他线程持有该锁，线程将获取该锁并进入临界区；如果另一个线程确实持有该锁，那么尝试获取该锁的线程将不会从该调用返回，直到获得该锁。注意上述代码缺乏正确的初始化，即所有锁必须正确初始化，一种方法是将锁设置为默认值：
```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
```
另一种更常用的方法是动态初始化：
```c
pthread_mutex_t lock;
int rc = pthread_mutex_init(&lock, NULL);
assert(rc == 0); //always check success
```
注意当锁用完时，还应调用pthread_mutex_destroy()。
还有另外两个用于获取锁的函数：
```c
int pthread_mutex_trylock(pthread_mutex_t* mutex);
int pthread_mutex_timedlock(pthread_mutex_t* mutex, 
                            struct timespec* abs_timeout);
```
如果锁已被占用，则trylock将失败；timedlock会在超时或获取锁后返回(以先发生者为准)，所以具有零超时的timedlock退化为trylock的情况。

#### 条件变量

当线程之间必须发生某种信号时，如果一个线程在等待另一个线程继续执行某些操作(即线程同步)，条件变量就很有用：
```c
int pthread_cond_wait(pthread_cond_t* cond, pthread_mutex_t* mutex);
int pthread_cond_signal(pthread_cond_t* cond);
```
一般用pthread_cond_t声明条件变量，并用PTHREAD_COND_INITIALIZER初始化。要使用条件变量，必须另外有一个与此条件相关的锁，在调用上述任何一个函数时，应该持有这个锁。wait函数使调用线程进入休眠状态，然后等待其他线程发出信号，而signal则是唤醒等待在某个条件变量上的睡眠线程。注意wait调用还有一个参数是互斥量，因为必须保证在wait调用时这个互斥量已上锁，然后wait()会把这个锁释放，并让调用线程休眠(原子地)，而当线程被唤醒时wait则会重新获取锁，然后再返回。典型用法如下：
```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
pthread_mutex_lock(&lock);
while (ready == 0)
    pthread_cond_wait(&cond, &lock);
pthread_mutex_unlock(&lock);
```
该线程检查变量ready是否已经被设置为0以外的值，如果没有，那么线程只是简单地调用等待函数以便休眠，直到其他线程唤醒它。唤醒线程的代码运行在另外某个线程中，如下：
```c
pthread_mutex_lock(&lock);
ready = 1;
pthread_cond_signal(&cond);
pthread_mutex_unlock(&lock);
```
注意在发出信号(调用signal和wait)及修改全局变量ready时，必须始终确保线程持有锁。

### 4. 线程的实现方式

用户线程：早期在用户态实现线程的管理与运行，由一组用户级的线程库函数来完成线程的管理，操作系统感知不到这类线程的存在。优点是线程切换只需在用户态下即可完成，开销小；缺点是一个线程发起系统调用而阻塞时，整个进程都会进入等待，并且不支持基于线程的处理机抢占，只能按进程分配CPU时间。

内核线程：由内核实现线程机制，由内核完成线程的创建、终止和管理以及维护TCB。优点是内核线程的调度由内核负责，一个内核线程处于阻塞状态时不影响其他的内核线程；缺点是线程切换会进入内核态，开销大。

### 5. 协程(coroutine)

协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程的函数体可以挂起并在任意时刻恢复执行。协程切换时，只切换寄存器，栈的切换则由用户态管理，所以没有进入内核态切换的开销，上下文切换非常快。
- 协程的内存占用比线程小；协程采用同步编程方式支持大规模并发I/O异步操作，不需要多线程的锁机制，不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态，所以执行效率比多线程高很多。
- 一个线程可以拥有多个协程，但协程无法使用多个CPU，协程是有限的并发执行，只有在协作点上yield才可以转移到另外一个协程去继续执行，其他时间都是某个执行流独占处理器执行，其好处是协程对人类来说理解起来很容易，但协程的缺点是无法并行。线程可以并发、并行，但需要我们自己来实现同步。

## 4.2 锁

POSIX库将锁称为互斥量(mutex)，因为它被用来提供线程之间的互斥，即当一个线程在临界区时，它能够阻止其他线程进入直到本线程离开临界区。注意POSIX的lock和unlock函数会传入一个参数，因为我们可能用不同的锁来保护不同的变量，这样可以增加并发。我们将给出一些锁的实现方法，并从三个方面来评价：是否完成最基本的要求(提供互斥)、公平性(是否会有竞争锁的线程饿死)、性能。

### 1. 控制中断

最早提供的互斥解决方案之一就是在临界区关闭中断，即lock关中断，unlock开中断。这个方法虽然简单，但是有很多缺点：首先它允许所有调用线程执行特权操作(开、关中断)，这很危险；其次这种方案不支持多处理器，如果多个线程运行在不同的CPU上，关中断也没用用；并且关中断可能导致中断丢失(比如磁盘完成了I/O但向CPU发送中断请求，CPU却无法收到)，从而导致严重的系统问题；最后该方法效率低，现代CPU对于关闭和打开中断的代码执行得较慢。

### 2. Peterson算法(软件实现，针对2个线程)

```c
int flag[2] = { 0,0 }; //表示两个线程进入临界区的意愿
int turn = 0; //用标签表示优先让哪个线程进入临界区
void lock() {
    flag[self] = 1; //表达自己想要进入临界区
    turn = other; //但选择优先让另一个线程进入, other = 1 - self
    while (flag[other] && turn == other);
    //如果另一个线程确实想进入，并且标签上也是另一个线程的名字，则等待
}
void unlock() { flag[self] = 0; }
```
这种方法确实能正确实现互斥，然而现代系统只需很少的硬件支持就能很容易实现锁，因此只靠软件实现锁的方法已经很少使用。

### 3. TestAndSet指令

为了理解该指令的想法，我们如下先实现一个不依赖TestAndSet指令的锁：
```c
typedef struct lock_t { int flag; } lock_t;
void init(lock_t* mutex) {
    mutex->flag = 0; //0 means lock is available
}
void lock(lock_t* mutex) {
    while (mutex->flag == 1); //test the flag
    mutex->flag = 1; //and now set it
}
void unlock(lock_t* mutex) { mutex->flag = 0; }
```
这种方法正确性就出现了问题，如果一个线程执行完while的判断后发现flag是0，此时开始执行另一个线程的while判断也发现flag是0，接下来他们都将执行flag置1的操作然后同时进入临界区。根本原因在于while检查和设置flag不是原子的，所以我们需要一条更强大的硬件指令，通常被称为TestAndSet(测试并设置)指令，在x86上也称为xchg(原子交换)指令：
```c
int TestAndSet(int* old_ptr, int new) {
    int old = *old_ptr;
    *old_ptr = new;
    return old;
}
```
它返回old_ptr指向的旧值，同时更新为new的新值，最关键的是这些代码是原子地执行的。于是我们可以实现以下简单的自旋锁：
```c
typedef struct lock_t { int flag; } lock_t;
void init(lock_t* mutex) {
    mutex->flag = 0; //0 means lock is available
}
void lock(lock_t* mutex) {
    while (TestAndSet(&mutex->flag, 1) == 1);
}
void unlock(lock_t* mutex) { mutex->flag = 0; }
```
自旋锁的一个问题是性能，因为线程在等待已经被持有的锁时采用了自旋等待(spin-waiting)的技术，就是不停地检查标志的值，它会占用CPU浪费时间；另一个问题是不公平，因为自旋的线程在竞争条件下可能会永远自旋。

### 4. 其他可实现自旋锁的硬件原语

==CompareAndSwap指令==
```c
int CompareAndSwap(int* ptr, int expected, int new) {
    int actual = *ptr;
    if (actual == expected) *ptr = new;
    return actual;
}

void lock(lock_t* mutex) {
    while (CompareAndSwap(&mutex->flag, 0, 1) == 1);
}
```
比较并交换指令的基本思路是检测ptr指向的值是否和expected相等，如果是则更新ptr所指的值为新值，否则什么也不做。可以看到它与TestAndSet指令实现的自旋锁工作方式很类似，但CompareAndSwap更强大。

==链接的加载(LoadLinked)指令和条件式存储(StoreConditional)指令==
```c
int LoadLinked(int* ptr) { return *ptr; }
int StoreConditional(int* ptr, int value) {
    if (no one has updated * ptr since the LoadLinked to this address) {
        *ptr = value;
        return 1; //success
    }
    else return 0; //failed to update
}

void lock(lock_t* mutex) {
    while (1) {
        while (LoadLinked(&mutex->flag) == 1);
        if (StoreConditional(&mutex->flag, 1) == 1) return;
        //otherwise：try it all over again
    }
}
void unlock(lock_t* mutex) { mutex->flag = 0; }
```
LoadLinked指令和典型加载指令类似，都是从内存中取出值存入一个寄存器。关键区别来自StoreConditional指令，只有上一次加载的地址在期间都没有更新时才会成功，同时更新刚才LoadLinked的地址的值，成功时返回1，并将ptr指的值更新为value，失败则返回0并且不会更新值。用这两条指令实现如上的锁，如果一个线程加载并判断flag是0(说明锁可用)，然后切换到另一个线程加载并判断flag是0，此时再执行下一条if判断发现flag未被更新，于是上锁(更改flag为1)，而如果之前那个线程执行下一条if判断，发现flag已被更新，于是条件存储指令返回0，开始重新循环。

==获取并增加(FetchAndAdd)指令==
```c
int FetchAndAdd(int* ptr) {
    int old = *ptr;
    *ptr = old + 1;
    return old;
}
typedef struct lock_t { int ticket; int turn; } lock_t;
void init(lock_t* mutex) {
    mutex->ticket = 0; mutex->turn = 0;
}
void lock(lock_t* mutex) {
    int myturn = FetchAndAdd(&mutex->ticket);
    while (mutex->turn != myturn);
}
void unlock(lock_t* mutex) { FetchAndAdd(&mutex->turn); }
```
这个方案使用了ticket和turn两个变量来构建锁。如果变量希望获取锁，就对ticket执行一个原子的获取并增加指令，当某个线程的myturn \=\= turn时就轮到它进入临界区。unlock则是增加turn，使得下一个等待线程可以进入临界区。不同于之前的方法，本方法能够保证所有线程都能抢到锁，只要一个线程对ticket执行了获取并增加指令，它最终就一定会被调度，从而满足公平性。

### 5. 使用队列将自旋改成休眠

原子指令的硬件支持让我们实现了正确、公平(通过ticket锁)的锁，但是一直自旋的低性能问题没有解决。一种简单的想法是在自旋的时候操作系统用一条原语yield()主动放弃CPU，然而采用轮转调度程序，很多线程竞争一把锁，就会有很多线程一直处于运行然后让出这种模式，直到持有锁的线程再次运行，这样的上下文切换成本依然很高，并且甚至可能导致某一个线程一直处于让出的循环然后饿死。因此，更好的做法是，操作系统用一个队列来保存等待锁的线程，并且(Solaris)提供两个系统调用：park()能够让调用线程休眠，unpark(TID)能唤醒TID标识的线程，可以用这两个调用来实现锁，让调用者在获取不到锁时睡眠，在锁可用时被唤醒。(Linux中是用futex_wait和futex_wake两个调用)
```c
typedef struct lock_t {
    int flag; int guard; queue_t* q;
} lock_t;
void init(lock_t* m) {
    m->flag = 0; m->guard = 0; queue_init(m->q);
}
void lock(lock_t* m) {
    while (TestAndSet(&m->guard, 1) == 1); //acquire guard lock by spinning
    if (m->flag == 0) {
        m->flag = 1; //lock is acquired
        m->guard = 0;
    }
    else {
        queue_add(m->q, gettid());
        m->guard = 0;
        park();
    }
}
void unlock(lock_t* m) {
    while (TestAndSet(&m->guard, 1) == 1);
    if (queue_empty(m->q))
        m->flag = 0; //let go of lock; no one wants it
    else
        unpark(queue_remove(m->q)); //hold lock for next thread
    m->guard = 0;
}
```
注意其中的guard基本上起到了自旋锁的作用，保证lock和unlock中的代码能够被互斥地执行，所以这个方法并没有完全避免自旋等待，但是这个自旋等待的时间是很有限的(不是用户定义的临界区，只是在lock和unlock代码中的几个指令)，因此仍然可以认为这种方法是合理的。还要注意这种方案可能导致唤醒/等待竞争，如果一个线程将要执行park()，此时切换到另一个正在释放锁的线程，它执行完unpark后就导致了原来线程执行park()，然后原线程就会一直休眠下去。为了避免这个情况，操作系统提供了另一个系统调用setpark()来解决这个问题，一个线程调用setpark()来表明自己马上要park，如果刚好另一个线程被调度并且调用了unpark，那么后续的park调用就会直接返回，而不是一直睡眠。于是可以将lock中的相关部分改成
```c
queue_add(m->q, gettid());
setpark();
m->guard = 0;
park();
```

## 4.3 条件变量

### 1. 生产者消费者问题(有界缓冲区问题)

问题：假设有多个生产者线程和多个消费者线程，生产者把生成的数据项放入缓冲区，消费者从缓冲区取走数据项，只有缓冲区没满时，生产者才能把数据放入缓冲区，只有缓冲区不空时，消费者才能从缓冲区取走数据项，所以必须提供同步机制来访问该有界缓冲区。我们首先仅用互斥锁来实现它：
```c
int buffer[MAX];
int fill_ptr = 0;
int use_ptr = 0;
int count = 0;
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
 
void put(int value) {
    buffer[fill_ptr] = value;
    fill_ptr = (fill_ptr + 1) % MAX;
    count++;
}
int get() {
    int tmp = buffer[use_ptr];
    use_ptr = (use_ptr + 1) % MAX;
    count--;
    return tmp;
}
 
void producer() {
    while (1) {
    retry:
        pthread_mutex_lock(&lock);
        if (count == MAX) {
            pthread_mutex_unlock(&lock);
            goto retry;
        }
        put(data);
        pthread_mutex_unlock(&lock);
    }
}
void consumer() {
    while (1) {
    retry:
        pthread_mutex_lock(&lock);
        if (count == 0) {
            pthread_mutex_unlock(&lock);
            goto retry;
        }
        int tmp = get();
        pthread_mutex_unlock(&lock);
    }
}
```
这一方法固然正确，并且调用的库函数pthread_mutex_lock在锁竞争时也不会发生自旋，但是线程本身可能发生自旋检查(如上不断执行goto)，我们希望通过某种变量来等待条件变真(比如在consumer中如果count为0则直接让该线程休眠，一旦count大于0则被唤醒)，从而降低系统开销。

### 2. 条件变量

线程可以使用条件变量(condition variable)来等待一个条件变成真。条件变量是一个显式队列，当条件不满足时线程可以把自己加入队列后休眠(调用wait)，等待该条件；当另外一个线程将条件变为真后，就可以唤醒一个(调用signal)或全部(调用broadcast)等待线程。接下来我们尝试用条件变量来完成生产者消费者问题的同步。

初次尝试：
```c
void producer() {
    while (1) {
        pthread_mutex_lock(&lock);
        if (count == MAX)
            pthread_cond_wait(&cond, &lock);
        put(data);
        pthread_cond_signal(&cond);
        pthread_mutex_unlock(&lock);
    }
}
void consumer() {
    while (1) {
        pthread_mutex_lock(&lock);
        if (count == 0)
            pthread_cond_wait(&cond, &lock);
        int tmp = get();
        pthread_cond_signal(&cond);
        pthread_mutex_unlock(&lock);
    }
}
```
这个方案有两个严重的问题：首先是wait之前的if语句出现的问题，假设有两个消费者线程C1和C2，以及一个生产者进程P1，一开始C1运行直到wait睡眠，然后P1运行直到signal唤醒等待线程，此时C2抢先运行，获取了缓冲区中的数据，然后C1开始运行从wait返回，之后调用get()发生错误(因为此时缓冲区为空)。这就是信号的Mesa语义：发信号给线程只是唤醒它们，暗示状态发生了变化(这个例子中就是缓冲区不空了)，但并不会保证在它运行之前状态一直是期望的情况。修复这个问题很简单，只需将两个线程中的if都改成while即可，根据Mesa语义，我们在使用条件变量时最好总是使用while循环。
但上述方案即使如此修改后也还有另一个问题，假设C1和C2都开始运行后睡眠了，然后P1运行唤醒C1，之后P1继续运行直到睡眠(假设MAX=1)，C1返回后进入while循环发现缓冲区是满的，于是继续运行后唤醒C2，然而C2和C1继续运行下去都会发现缓冲区为空而睡眠，从而导致三个线程全都睡眠了。所以我们应该保证消费者唤醒生产者，而不能唤醒消费者，所以需要使用两个条件变量以便正确发出信号，由此我们得到了以下的正确方案。

正确方案：
```c
void producer() {
    while (1) {
        pthread_mutex_lock(&lock);
        while (count == MAX)
            pthread_cond_wait(&empty, &lock);
        put(data);
        pthread_cond_signal(&fill);
        pthread_mutex_unlock(&lock);
    }
}
void consumer() {
    while (1) {
        pthread_mutex_lock(&lock);
        while (count == 0)
            pthread_cond_wait(&fill, &lock);
        int tmp = get();
        pthread_cond_signal(&empty);
        pthread_mutex_unlock(&lock);
    }
}
```
我们常常用pthread_cond_broadcast()代替上面的pthread_cond_signal()，从而唤醒所有的等待线程，因为在有些情况下唤醒某一个线程可能并不满足所需的条件，而直接唤醒所有线程就确保了所有应该唤醒的线程都被唤醒，当然不利的一面是可能会影响性能。这种条件变量也称为覆盖条件，因为它能覆盖所有需要唤醒线程的场景。

### 3. 管程

信号量的大量同步操作分散在各个线程中不便于管理，为此引入了管程(monitor)这种同步工具。管程是一种用于多线程互斥访问共享资源的程序结构，无须程序员自己实现互斥，从而降低了死锁发生的可能性。同时管程内部提供了条件变量，可以让程序员更方便地实现线程同步。

管程的基本特征：管程把对共享资源的操作封装起来，管程内的共享变量只能被管程内的函数所访问，一个线程只有通过调用管程内的函数才能进入管程访问共享资源；任一时刻最多只有一个线程执行管程代码。

管程的主要组成：一个锁(控制管程代码的互斥访问)、0个或者多个条件变量、条件变量队列、入口等待队列、紧急等待队列等等

## 4.4 信号量

### 1. 信号量的定义

信号量是有一个整数值的对象，在POSIX标准中，可以用原语sem_wait()和sem_post()来操作它(也分别称为P操作和V操作)，因为信号量的初始值能够决定其行为，所以必须初始化信号量。
```c
#include <semaphore.h>
sem_t S;
sem_init(&S, 0, x);
int sem_wait(sem_t* s) {
    decrement the value of semaphore s by one
    wait if value of semaphore s is negative
}
int sem_post(sem_t* s) {
    increment the value of semaphore s by one
    if there are one or more threads waiting, wake one
}
```
- init通过第三个参数将S的值初始化为x，而第二个参数一般都设为0，表示信号量是在同一进程的多个线程共享的。
- wait函数将信号量的值先减1，如果信号量的值仍非负，则直接返回，否则会让调用线程挂起。可见当信号量的值为负数时，这个值就是等待线程的个数。
- post函数将信号量的值加1，然后唤醒一个睡眠的线程。

### 2. 信号量用作锁

```c
sem_t m;
sem_init(&m, 0, 1);
 
sem_wait(&m);
critical section;
sem_post(&m);
```
将信号量的值初始化为1，然后把临界区用一对P、V操作环绕就实现了锁的功能。因为锁只有两个状态(持有和没持有)，所以这种用法有时也叫作二值信号量。

### 3. 信号量用作条件变量

我们以一个线程创建另外一线程，并且等待它结束为例：
```c
sem_t s;
void* child(void* arg) {
    printf("child\n");
    sem_post(&s);
}
int main() {
    sem_init(&s, 0, 0);
    pthread_t c;
    pthread_create(c, NULL, child, NULL);
    sem_wait(&s); 
    printf("parent\n");
    return 0;
}
```
注意上述例子中信号量应该被初始化为0

![](/zzimages/20230401215029.png)

### 4. 信号量实现生产者消费者问题

初次尝试：
```c
int buffer[MAX];
int fill_ptr = 0;
int use_ptr = 0;
sem_t empty;
sem_t fill;
sem_t mutex;
 
void put(int value) {
    buffer[fill_ptr] = value;
    fill_ptr = (fill_ptr + 1) % MAX;
}
int get() {
    int tmp = buffer[use_ptr];
    use_ptr = (use_ptr + 1) % MAX;
    return tmp;
}
 
void producer() {
    while (1) {
        sem_wait(&mutex);
        sem_wait(&empty);
        put(data);
        sem_post(&fill);
        sem_post(&mutex);
    }
}
void consumer() {
    while (1) {
        sem_wait(&mutex);
        sem_wait(&fill);
         int tmp = get();
        sem_post(&empty);
        sem_post(&mutex);
    }
}
int main() {
    sem_init(&empty, 0, MAX);
    sem_init(&fill, 0, 0);
    sem_init(&mutex, 0, 1);
    //...
}
```
类似于条件变量实现的方式，我们将锁和条件变量相应地用信号量实现。然而这段代码有一个很严重的问题，假设有一个消费者线程和一个生产者线程，消费者线程先运行，获得锁，然后执行wait(&fill)进入休眠，注意此时消费者仍持有锁，接下来运行生产者线程，直接在wait(&mutex)就进入休眠，于是就出现了循环等待，发生死锁。要解决这个问题，只需减少锁的作用域，把获取和释放互斥量的操作调整为紧挨着临界区即可(实现互斥的P操作一定要在实现同步的P操作之后，而V操作不会导致进程阻塞)：

正确方案：
```c
void producer() {
    while (1) {
        sem_wait(&empty);
        sem_wait(&mutex);
        put(data);
        sem_post(&mutex);
        sem_post(&fill);
    }
}
void consumer() {
    while (1) {
        sem_wait(&fill);
        sem_wait(&mutex);
         int tmp = get();
        sem_post(&mutex);
        sem_post(&empty);
    }
}
int main() {
    sem_init(&empty, 0, MAX);
    sem_init(&fill, 0, 0);
    sem_init(&mutex, 0, 1);
    //...
}
```

### 5. 信号量的实现

我们用底层的同步原语(锁和条件变量)来实现自己的信号量，名字叫作Zemaphore

```c
typedef struct _Zem_t {
    int value;
    pthread_cond_t cond;
    pthread_mutex_t lock;
} Zem_t;
 
void Zem_init(Zem_t* s, int value) {
    s->value = value;
    s->cond = PTHREAD_COND_INITIALIZER;
    s->lock = PTHREAD_MUTEX_INITIALIZER;
}
void Zem_wait(Zem_t* s) {
    pthread_mutex_lock(&s->lock);
    while (s->value <= 0)
        pthread_cond_wait(&s->cond, &s->lock);
    s->value--;
    pthread_mutex_unlock(&s->lock);
}
void Zem_post(Zem_t* s) {
    pthread_mutex_lock(&s->lock);
    s->value++;
    pthread_cond_signal(&s->cond);
    pthread_mutex_unlock(&s->lock);
}
```
注意我们wait的实现稍有不同，事实上value的值永远不会小于0，这一行为更容易实现，并符合现有的Linux实现。虽然信号量很简单，但是往往用锁和条件变量会更实用。

## 4.5 经典同步问题

### 1. 多生产者-多消费者问题

![](/zzimages/20230401215355.png)

![](/zzimages/20230401215403.png)

本题中也可以不设置专门的互斥变量mutex，其原因在于本题中的缓冲区大小为1，在任何时刻，apple、orange、plate三个同步信号量中最多只有一个是1，因此在任何时刻最多只有一个进程的P操作不会被阻塞并顺利进入临界区，所以不会出现多个进程同时访问临界区的现象。

### 2. 吸烟者问题

![](/zzimages/20230401215431.png)

![](/zzimages/20230401215441.png)

### 3. 读者-写者问题

问题：有读者和写者两组并发进程，共享一个文件，要求：允许多个读者同时读文件；同一时刻只允许一个写者写文件(读者此时也无法读)。
```c
sem_t rw; //用于实现对共享文件的互斥访问，初始化为1
int count = 0; //记录当前有几个读进程在访问文件
sem_t mutex; //保证对变量count的互斥访问，初始化为1
sem_t w; //用于防止写进程饥饿，初始化为1
 
void write() {
    while (1) {
        sem_wait(&w);
        sem_wait(&rw); //写之前加锁
        //写文件...
        sem_post(&rw); //写完后解锁
        sem_post(&w);
    }
}
void read() {
    while (1) {
        sem_wait(&w);
        sem_wait(&mutex); //各读进程互斥访问count
        if (count == 0)
            sem_wait(&rw); //由第一个读进程负责读之前加锁
        count++;
        sem_post(&mutex);
        sem_post(&w); //此时释放w，就可防止写进程饥饿
        //读文件...
        sem_wait(&mutex); //各读进程互斥访问count
        count--;
        if (count == 0)
            sem_post(&rw); //由最后一个读进程负责读完后解锁
        sem_post(&mutex);
    }
}
int main() {
    sem_init(&rw, 0, 1);
    sem_init(&mutex, 0, 1);
    sem_init(&w, 0, 1);
    //...
}
```

### 4. 哲学家就餐问题

问题：有5位哲学家围成一个圆桌，每两位哲学家之间有一把餐叉(一共5把)，哲学家有时要思考一会，不需要餐叉，有时又要就餐，而一位哲学家只有同时拿到了左手边和右手边的两把餐叉后才能吃东西。一个自然的想法是如下方案：
```c
//5个信号量都初始化为1，虽然这种初始化方式只是伪代码
sem_t forks[5] = { 1,1,1,1,1 }; 
void eat(int i) { //i号哲学家线程
    while (1) {
        sem_wait(&forks[i]); //拿左
        sem_wait(&forks[(i + 1) % 5]); //拿右
        //吃饭...
        sem_post(&forks[i]); //放左
        sem_post(&forks[(i + 1) % 5]); //放右
    }
}
```

然而一旦5个线程并发地拿起左边的餐叉，就会一直循环等待右边的餐叉，发生死锁。我们可以修改某个哲学家取餐叉的顺序，比如第4号哲学家选择先取右边的餐叉，再取左边的餐叉，得到以下正确方案：

```c
void eat(int i) { //i号哲学家进程
    while (1) {
        if (i == 4) {
            sem_wait(&forks[(i + 1) % 5]); //拿右
            sem_wait(&forks[i]); //拿左
        }
        else {
            sem_wait(&forks[i]); //拿左
            sem_wait(&forks[(i + 1) % 5]); //拿右
        }
        //吃饭...
        sem_post(&forks[i]); //放左
        sem_post(&forks[(i + 1) % 5]); //放右
    }
}
```

虽然这个方案正确，但事实上我们大可不必用这么特殊的解决方法。回顾我们最初的方案，其失败的原因在于我们自作聪明地让哲学家们先取左边餐叉再取右边餐叉，而事实上一个哲学家能够吃饭当且仅当他能够同时得到左右两边的餐叉，因此只要不满足这个条件，就让他等待即可，所以下述的解决方案才是解决这类问题的万能方法(我们用锁和条件变量来实现)：

```c
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t cv = PTHREAD_COND_INITIALIZER;
bool avail[5] = { 1,1,1,1,1 };
 
void eat(int i) { //i号哲学家进程
    while (1) {
        pthread_mutex_lock(&mutex);
        while (!(avail[i] && avail[(i + 1) % 5])) 
            pthread_cond_wait(&cv, &mutex);
        avail[i] = avail[(i + 1) % 5] = false;
        pthread_mutex_unlock(&mutex);
        //吃饭...
        pthread_mutex_lock(&mutex);
        avail[i] = avail[(i + 1) % 5] = true;
        pthread_cond_broadcast(&cv);
        pthread_mutex_unlock(&mutex);
    }
}
```

除此之外，我们还有更简单和直接的方法：

![](/zzimages/20230401215811.png)

事实上，由于吃饭的时间远大于请求服务员的时间，所以管理叉子的服务员并不会成为性能的瓶颈，甚至如果一个服务员搞不定，就分多个服务员，总之可以把系统设计好，使集中管理不再成为瓶颈。

## 4.6 常见并发问题

### 1. 非死锁缺陷

非死锁缺陷主要有两类：
- 违反原子性缺陷：违反了多次内存访问中预期的可串行性(即代码段本意是原子的，但在执行中并没有强制实现原子性)。一般只要给共享变量的访问加上互斥锁即可解决该问题。
- 违反顺序缺陷：两个内存访问的预期顺序被打破(即A应该在B之前执行，但是实际运行中却不是这个顺序)。一般用条件变量实现同步即可解决该问题。

### 2. 死锁缺陷

死锁(deadlock)是指各线程互相等待对方手里的资源，导致各线程都阻塞，无法向前推进的现象(注意与饥饿区分，饥饿是指由于长期得不到想要的资源，某线程无法向前推进的现象)。

#### 死锁产生的必要条件

只要以下4个条件之一不满足，就不会发生死锁：
- 互斥：只有对必须互斥访问的资源的竞争才可能导致死锁
- 持有并等待：线程应已经持有了至少一个资源，同时又在等待其他资源
- 非抢占：线程获得的资源不能被抢占
- 循环等待：存在一种线程资源的循环等待环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。(注意循环等待不一定是死锁的充分条件，如果同类资源数大于1，则即使有循环等待也未必发生死锁；然而如果系统中每类资源都只有一个，那么循环等待就是死锁的充分必要条件了)

#### 死锁的处理策略

==死锁预防==：破坏死锁产生的4个必要条件中的一个或几个
- 破坏循环等待：让代码不产生循环等待是最常用的死锁预防技术。最直接的方法就是获取锁时提供一个全序，比如系统共有两个锁L1和L2，那么我们每次都先申请L1然后申请L2就可以避免死锁(可以根据锁的地址大小来定义锁的申请顺序)，因为这样的严格顺序避免了循环等待；如果锁的全序难以做到，也可以用偏序安排锁的获取并避免死锁(Linux中的内存映射代码就是一个偏序锁的例子)。这种死锁预防技术需要细致的锁策略的设计和实现。
- 破坏持有并等待：可以通过原子地抢锁来预防死锁。比如一个线程需要L1和L2两个锁，那么将这段代码再用一个全局锁prevention包围，只有先抢到prevention锁后，线程才能继续运行，于是申请L1和L2时就变成了原子操作。该方案降低了并发，资源利用率低，并且可能导致饥饿。
- 破坏非抢占：利用trylock()函数尝试获得锁，返回-1表示锁已被占有。
    ```c
    top:
        lock(L1);
        if (trylock(L2) == -1) {
            unlock(L1);
            goto top;
        }
    ```
    用以上方案可以实现无死锁的加锁方法。但是会导致活锁(livelock)，两个线程可能一直重复这一序列，又同时抢锁失败，即系统一直在运行这段代码，但是又不会有进展，这就是活锁。当然我们也可以在循环结束时候先随机等待一个时间然后再重复，从而解决活锁的问题。这种方案实现起来比较困难，而且反复申请和释放资源会增加系统开销。
- 破坏互斥：采用无等待数据结构的思想，通过强大的硬件指令来构造出不需要锁的数据结构。如下我们用一个原子指令CAS来给某个变量增加特定的数值：
    ```c
    int CAS(int* address, int expected, int new) {
        if (*address == expected) {
            *address = new;
            return 1;
        }
        return 0;
    }
    void AtomicIncrement(int* value, int amount) {
        do {
            int old = *value;
        } while (CAS(value, old, old + amount) == 0);
    }
    ```
    这种方式没有使用锁就实现了变量的更新，自然也不会发生死锁，但可能发生活锁。然而很多时候都无法破坏互斥条件。

==死锁避免==：通过调度的方式防止系统进入不安全状态，从而避免死锁。我们需要了解全局的信息，包括不同线程在运行中对锁的需求情况，从而使得后续的调度能够避免产生死锁。例如线程T1要用锁L1和L2，线程T2要用锁L1和L2，线程T3要用锁L2，则只需让线程T1和T2不同时运行即可(比如线程T1执行完后再运行T2)，注意线程T3只需要一个锁，所以T3是不会死锁的。也可以用Dijkstra提出的银行家算法来避免死锁：

![](/zzimages/20230401220509.png)

![](/zzimages/20230401220520.png)

![](/zzimages/20230401220527.png)

可惜的是，这些方案的适用场景很局限，首先要知道所有任务所需的锁就很困难，除此之外，如果每个线程都需要锁T1和T2，那么让他们先后执行会限制并发，严重影响性能。

==死锁的检查和恢复==：允许死锁偶尔发生，不过操作系统会负责检查到死锁的发生，然后采取某种措施解除死锁。很多数据库系统使用了死锁检测和恢复技术，死锁检测器会定期运行，通过构建资源图来检查循环，当循环(死锁)发生时系统需要重启。

![](/zzimages/20230401220553.png)

![](/zzimages/20230401220558.png)

![](/zzimages/20230401220604.png)

![](/zzimages/20230401220610.png)

# 第5章 持久性-文件系统

## 5.1 文件和目录

文件是一个字节序列，每个文件都有一个低级名称，称为inode号(inumber)。目录是一种特殊的文件，但其内容非常具体：包含(用户可读名称，低级名称)条目的列表。UNIX类操作系统将所有一切均抽象成文件，提供了统一的接口，方便应用程序调用。下面我们讨论文件系统的接口。

Linux系统IO函数：
```c
int open(const char* pathname, int flags);
int open(const char* pathname, int flags, mode_t mode);
int close(int fd);
ssize_t read(int fd, void* buf, size_t count);
ssize_t write(int fd, const void* buf, size_t count);
off_t lseek(int fd, off_t offset, int whence);
int stat(const char* pathname, struct stat* statbuf);
int lstat(const char* pathname, struct stat* statbuf);
```
详细用法参考Linux系统编程入门笔记。

### 硬链接和软链接

link()系统调用有两个参数：一个旧路径名和一个新路径名，它将新的文件名硬链接到旧的文件名。命令行程序ln用于硬链接，例如ln file file2就是创建了文件file的一个硬链接file2。注意link只是在要创建链接的目录中创建了另一个名称，并将其指向原有文件的相同inode号，该文件并不以任何方式复制。注意如果删除了file，我们仍可以读取file2，因为调用unlink时会检查其inode中的引用计数(表明有多少不同的文件名已链接到这个inode)，然后删除该文件名称与该inode号之间的链接，并减少引用计数，只有当引用计数为0时文件系统才会释放inode和相关数据块，从而真正删除该文件。

由于不能创建目录的硬链接，也不能硬链接到其他磁盘分区中的文件(因为inode号在特定文件系统中是唯一的，而不是跨文件系统)，所以人们创建了软链接，也称符号链接。只需在程序ln中使用-s标志即可创建软链接。软链接本身实际上是一个不同类型的文件(它是文件系统的第三种类型)，它将链接指向文件的路径名作为链接文件的数据。软链接可能造成悬空引用：如果删除原始文件，就会导致软链接指向不再存在的路径名。

### 创建并挂载文件系统

从许多底层文件系统组建完整的目录树，一般是先制作文件系统，然后挂载它们，使其内容可以访问。通常用mkfs工具创建文件系统，为该工具提供一个设备(如磁盘分区/dev/sda1)和一种文件系统类型(如ext3)作为输入，它就在该磁盘分区上写入一个空文件系统，从根目录开始。创建了这样的文件系统后，就需要在统一的文件系统树中进行访问，一般使用mount程序，以现有目录作为目标挂载点，即将新的文件系统粘贴到目录树的这个点上。例如在命令行输入以下命令：mount -t ext3 /dev/sda1 /home/users ，于是路径名/home/users/现在指的是新挂载目录的根，可见mount将所有文件系统统一到一棵树中，而不是拥有多个独立的文件系统，这让命名统一而且方便。

## 5.2 简单的文件组织

### 1. 整体组织

我们首先介绍一个简单文件系统(VSFS, Very Simple File System)来实现虚拟文件系统(虚拟文件系统是对所有不同文件系统的抽象，主要为上层用户提供相同的文件和文件系统接口，管理所有文件和文件系统关联的数据结构，并且高效查询例程、遍历文件系统，同时与下层的各种不同文件系统模块进行交互)。将磁盘分成块(block)(注意扇区是磁盘最小的物理存储单元(一般512B)，操作系统不与扇区直接交互；而磁盘块是文件系统读写数据的最小单位(一般4KB，一般与内存操作的最小单位页的大小相同)，由多个连续扇区组成，一个磁盘块只能放置一个文件)，例如一个64块(每块4KB)的磁盘，这些块的地址是从0到63，可以分为不同区域用作不同用途：
- 用于存放用户数据的磁盘区域称为数据区域(比如8到63块)
- 文件系统用inode记录每个文件的信息，存放inode的区域称为inode表，它是保存了一个磁盘上inode的数组(比如3到7块)
- 我们用位图来记录inode或数据块是空闲还是已分配(空闲空间管理)，数据位图用于记录数据块是否空闲，inode位图用于记录inode是否空闲(比如第1块用作inode位图，第2块用作数据位图)。位图是一种高效的空闲空间管理方式，早期文件系统也会使用空闲列表来管理空闲空间。
- 第0块用作超级块(文件卷控制块)，它包含关于该文件系统的信息，比如文件系统中有多少个inode和数据块、inode表的开始位置、一些幻数来标识文件系统类型等等。在挂载文件系统时，操作系统将首先读取超级块加入内存，初始化各种参数，然后将该卷添加到文件系统树中，当卷中的文件被访问时系统就会知道在哪里查找所需的磁盘上的结构。

注：UNIX的空闲空间管理采用成组链接法

![](/zzimages/20230403195537.png)

![](/zzimages/20230403195543.png)

![](/zzimages/20230403195549.png)

### 2. 文件组织

inode(index node, 索引节点)是用于保存所有关于该文件的信息(元数据)的结构，包括文件类型(如文件、目录、软链接)、大小、拥有者与群组、分配给它的块数、保护信息、一些时间信息、其数据块在磁盘上的位置等等。每个inode都由inumber隐式引用，根据inumber和inode表起始地址可以直接计算出相应inode的磁盘地址，例如要读取32号inode，由于inode表起始地址为12KB，假设每个inode为256B，则32号inode的磁盘地址就是$12KB+32\times 256B=20KB$，由于磁盘使按扇区寻址的，每个扇区大小为512B，所以它位于第40号扇区。

inode中最重要的是引用数据块的位置，一个inode中一般有多个直接指针和一个间接指针。直接指针指向属于该文件的一个数据块，而间接指针则指向一个间接块(来自磁盘的数据区域)，间接块中的内容都是指针，每个指针都指向该文件的一个数据块。如果某个文件特别大，也可使用更多层的间接索引。事实上，大多数文件很小，所以一般用多个直接指针即可。

- 另一种方法是不需要指向文件的每个块的指针，只需要一个指针加一个长度(称为范围)即可指定文件的磁盘位置。只有一个范围是有局限的，因为分配文件时可能无法找到连续的磁盘可用空间块，所以一般允许多个范围，从而在文件分配期间给予文件系统更多自由。这种方法不够灵活但更紧凑，并且比上述多级索引的方法使用更少的元数据，如果磁盘上有足够的可用空间并且文件可以连续布局，基于范围的方法都能正常工作。
- 还有一种更古老的方法，即使用链表，在一个inode中只记录文件的第一个数据块的指针，而在该数据块的末尾添加下一个数据块的指针。为了提高效率，内存中会保留文件分配表，该表用数据块的地址来索引，一个条目的内容就是该数据块的下一个数据块的地址。

### 3. 目录组织

目录的内容就是文件元数据：

|inum|reclen|strlen|name|
|---|---|---|---|
|5|4|2|.|
|2|4|3|..|
|12|4|4|foo|
|13|4|4|bar|
|24|8|7|foobar|

目录在磁盘上的内容可能如上所示，每个条目有一个inode号，记录长度(名称的总字节数加上所有的剩余空间)，字符串长度(名称的实际长度)，条目的名称。注意每个目录都有两个额外的条目，点目录就是当前目录，点点目录就是父目录。删除一个文件会在目录中间留下一段空白，因此应该有一些方法来标记它，比如用一个保留的inode号0，这种删除是使用记录长度的一个原因：新条目可能会重复使用旧的、更大的条目，从而在其中留有额外的空间。

## 5.3 读写文件的详细过程

### 1. 读取和关闭文件

发出一个open("/wsy/bar", O_RDONLY)调用后，文件系统首先需要遍历路径名来找到文件bar的inode：文件系统先读入根目录的inode所在的块(根的inode号是已知的，一般UNIX中根的inumber是2)，然后查找其指向数据块的指针从而读取该目录数据块，在目录中查找wsy的条目并得到对应inode号，然后递归遍历路径名，最终找到bar的inode号。open的最后一步是将bar的inode读入内存，并进行权限检查，在进程的打开文件表中分配一个文件描述符，并将它返回给用户。可见open导致的I/O量与路径名的长度成正比，而对于大型目录，可能需要读取多个数据块才能找到所需条目。

打开文件后，可以发出read()系统调用，第一次读取(除非调用过lseek()，否则就在偏移量0处)将在文件的第一个数据块中读取，系统查阅inode以查找这个块的位置。读取操作也会用新的最后访问时间更新inode，并且也会更新此文件描述符所在的打开文件表，比如更新文件偏移量等等。

关闭文件要做的工作很少，它将进程的打开文件表中该文件描述符对应的表项删除。事实上，一共有两种打开文件表，一种是==每个进程私有的打开文件表==(每个表项包含文件描述符、文件名、==文件偏移量==(即读写指针，保存最近一次读写位置)、==访问权限==、==系统表索引号==等)，另一种是==系统的打开文件表==(整个系统只有一张，每个表项包括==索引号==、文件名、==磁盘地址==、==打开计数器==(用于记录有多少个进程打开了此文件)等)，所以open操作还会使系统的打开文件表对应表项的打开计数器加1(如果没有该表项则创建该表项)，close操作还会使系统的打开文件表对应表项的打开计数器减1(若打开计数器为0了就会删除该表项)，而删除文件时也会先检查系统的打开文件表，如果该文件已被打开则会提示"暂时无法删除该文件"。

### 2. 创建和写入文件

首先发出一个open调用来创建或打开文件。如果是创建文件，则文件系统要做很多I/O：读取inode位图(查找空闲inode)，写入inode位图(将其标记为已分配)，写入新的inode(初始化inode)，写入目录的数据(将文件名链接到它的inode号)，读写目录inode来更新。总而言之，创建一个文件不仅要分配一个inode，还要在包含新文件的目录中分配空间。

打开文件后可以写入文件，写入文件时首先要分配一个块(除非块被覆写)，于是要读取数据位图(查找空闲数据块)，写入数据位图(将其标记为已分配)，读取inode和写入inode(为了更新块的位置)，最后再向数据块写入真正的内容。

### 3. 缓存和缓冲

读写文件会导致大量的I/O而降低性能，所以大多数文件系统使用系统内存DRAM来缓存重要的块。早期的文件系统采用静态划分的方式，比如固定使用10%的内存来缓存常用的块，但这种方式可能导致浪费。现代系统都采用动态划分方式，即将虚拟内存页面和文件系统页面集成到统一页面缓存中，通过这种方式可以在虚拟内存和文件系统之间更灵活地分配内存，具体取决于在给定时间谁需要更多的内存。

高速缓存能显著提高读取的性能，却不能减少写入流量，所以一般采用写缓冲(write buffering)的方式。通过延迟写入，文件系统可以将一些更新编成一批然后一起写入，从而减少I/O次数；其次，通过将一些写入缓冲在内存中，系统可以立即调度后续的I/O，提高性能；最后，一些写入可以通过拖延来完全避免(比如写入文件后又删除了该文件)。

## 5.4 快速文件系统

### 柱面组

简单文件系统性能较差，快速文件系统(FFS，Fast File System)将磁盘划分为一些柱面组来改善性能，每个柱面组都要有一个超级块的副本(为了安全可靠性)、一个该柱面组的inode位图和数据位图、以及数据区域。柱面组的核心思想是相关的东西放一组，因为同一组中文件的访问不会导致很长的磁盘寻道时间(所以磁盘地址是(柱面号，盘面号，扇区号)，从而访问一段连续的地址大概率就是同一柱面组中的地址)。

- 目录的分配：找到一个目录分配较少的柱面组(希望跨组平衡目录)并且满足该组有大量空闲的inode(希望能分配较多文件在该目录下)，然后将目录数据和目录对应的inode分配在该组。
- 文件的分配：对于一般的小文件，将文件的数据块和其inode分配到相同的组，并且同一目录中的所有文件也应尽量放到与该目录相同的组。
- 大文件的分配：如果像上述文件分配方案一样把大文件的数据块直接填满一个组，就会导致同一目录下的其他文件无法再放置于这个组，导致性能降低。因此，对于大文件，首先将其inode中所有直接指针所指的数据块都放入同一个柱面组中，而每个间接块所指向的数据块放入另一个柱面组中(例如一个4KB的间接块，里面含有512个指针，指向512个数据块，即2MB的数据放入一个柱面组，再下一个4KB的间接块所指的2MB的数据放入另一个柱面组，以此类推)。

### 其他FFS的特点

如果对于很小的文件(如1KB)，为它分配4KB的块有很大的内部碎片，于是FFS引入了子块(每个子块512B)，于是1KB的文件将占用两个子块，直到文件增长到4KB数据后才会找一4KB块将子块复制到其中，并释放子块。这一过程效率较低，所以FFS修改了libc库，该库将缓冲写入，然后以4KB块的形式将它们发送到文件系统，从而在大多数情况下完全避免了子块的特殊情况。

FFS的磁盘布局采用交替编号。如果逻辑上相邻的扇区在物理上也相邻，由于磁头读完一个扇区的数据后需要一小段时间来处理(此时磁头继续在下一个扇区滑动)，于是要读取下一个扇区的时候就需要几乎再旋转一圈。因此，采用交替编号的策略，即让逻辑上相邻的扇区在物理上有一定间隔，就可以使读取连续逻辑扇区的旋转延迟时间很小。但这个方案毕竟也不太好(如果物理上间隔较大，也会有很高的延迟时间)，而现代磁盘更加智能，它们在内部读取整个磁道并将其缓冲在内部磁盘缓存中，然后在对该磁道的后续读取中就直接从该缓存中返回所需数据。

## 5.5 崩溃一致性

崩溃可能导致磁盘文件系统映像中的文件系统数据结构出现不一致性。例如一个应用需要为某个文件添加一个数据块，则必须对磁盘执行3次单独写入(更新inode、数据块、数据位图)，发出write()系统调用时，这些写操作通常不会立即发生，脏的inode、位图和新数据==先在内存(页面缓存page cache，或缓冲区缓存buffer cache)中存在一段时间==，当文件系统最终决定将它们写入磁盘时，文件系统将向磁盘发出必要的写入请求，然而如果写入操作中的一个或两个完成后发生崩溃，而不是全部3个，则文件系统可能处于不一致的状态。这就是我们要解决的崩溃一致性问题(crash-consistency problem)，早期采用文件系统检查程序(fsck, file system checker)的方法，现在一般采用日志记录(journaling，也称为预写日志，write-ahead logging)的方法。

### 1. 文件系统检查程序

早期UNIX采用工具fsck来查找不一致的事情，然后再修复它们(重启时)，确保文件系统元数据内部一致。主要检查超级块、空闲块、inode状态、inode链接、重复指针、坏块、目录检查等等。这种方法最大的问题是扫描整个磁盘所耗费的时间太久了。

### 2. 日志

主要思想是更新磁盘时，在覆写结构之前，首先在磁盘的某个地方写下一点小注记来描述将要做的事情，从而保证在发生崩溃后也能够返回查看注记来重试。

#### 数据日志

主要步骤如下：
![](/zzimages/20230403200509.png)
![](/zzimages/20230403200518.png)

1. 日志写入：将事务的内容(包括事务开始块TxB，元数据块，数据块)写入日志，等待这些写入完成。
2. 日志提交：将事务提交块(TxE)写入日志，等待写完成，于是该事务被认为已提交。
3. 加检查点：将待处理的元数据和数据更新写入其最终的磁盘位置。
4. 释放：一段时间后，通过更新日志超级块，在日志中标记该事务为空闲。

注：TxB告诉我们有关此更新的信息，包括元数据块和数据块的最终磁盘地址，以及事务标识符(TID, transaction identifier)；TxE是该事务结束的标记，也会包含TID。注意磁盘提供原子性保证，即磁盘保证任何512字节写入都会发生或不发生，因此我们需要保证TxE是一个512字节的块。

#### 元数据日志

主要步骤如下：
1. 数据写入：将数据写入最终磁盘位置。
2. 日志元数据写入：将事务开始块TxB和元数据块写入日志。
3. 日志提交：等待1.和2.写入完成后，将事务提交块TxE写入日志，等待写完成，现在认为事务已提交。
4. 加检查点元数据：将元数据更新的内容写入其最终的磁盘位置。
5. 释放：一段时间后，通过更新日志超级块，在日志中标记该事务为空闲。

注：该方法无需将数据块写入日志，从而提高了效率。通过强制首先写入数据，文件系统可保证指针永远不会指向垃圾数据，这也是崩溃一致性的核心。

# 第6章 持久性-设备管理

## 6.1 内核I/O结构

### 1. 内核I/O结构

![](/zzimages/20230403200855.png)

### 2. I/O请求过程

![](/zzimages/20230403200915.png)

### 3. I/O执行模型的分类

阻塞I/O：基于阻塞 I/O(blocking I/O)模型的文件读系统调用(read)的执行过程是：用户进程发出 read 系统调用；内核发现所需数据没在 I/O 缓冲区中，需要向磁盘驱动程序发出 I/O 操作，并让用户进程处于阻塞状态；磁盘驱动程序把数据从磁盘传到 I/O 缓冲区后，通知内核（一般通过中断机制），内核会把数据从 I/O 缓冲区拷贝到用户进程的 buffer 中，并唤醒用户进程（即用户进程处于就绪态）；内核从内核态返回到用户态进程，此时 read 系统调用完成。

非阻塞I/O：基于非阻塞 IO（non-blocking I/O）模型的文件读系统调用(read)的执行过程：用户进程发出 read 系统调用；内核发现所需数据没在 I/O 缓冲区中，需要向磁盘驱动程序发出 I/O 操作，并不会让用户进程处于阻塞状态，而是立刻返回一个 error；用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作（这一步操作可以重复多次）；磁盘驱动程序把数据从磁盘传到 I/O 缓冲区后，通知内核（一般通过中断机制），内核在收到通知且再次收到了用户进程的 system call 后，会马上把数据从 I/O 缓冲区拷贝到用户进程的 buffer 中；内核从内核态返回到用户态的用户态进程，此时 read 系统调用完成。所以，在非阻塞式 I/O 的特点是用户进程不会被内核阻塞，而是需要不断的主动询问内核所需数据准备好了没有。

多路复用I/O：多路复用 I/O（I/O multiplexing）的文件读系统调用(read)的执行过程：对应的 I/O 系统调用是 select 和 epoll 等；通过 select 或 epoll 系统调用来不断的轮询用户进程关注的所有文件句柄或socket，当某个文件句柄或 socket 有数据到达了，select 或 epoll 系统调用就会返回到用户进程，用户进程再调用 read 系统调用，让内核将数据从内核的I/O 缓冲区拷贝到用户进程的 buffer 中。

信号驱动I/O：当进程发出一个 read 系统调用时，会向内核注册一个信号处理函数，然后系统调用返回，进程不会被阻塞，而是继续执行；当内核中的 IO 数据就绪时，会发送一个信号给进程，进程便在信号处理函数中调用 IO 读取数据。

异步I/O：用户进程发起 read 异步系统调用之后，立刻就可以开始去做其它的事；从内核的角度看，当它收到一个 read 异步系统调用之后，首先它会立刻返回，所以不会对用户进程产生任何阻塞情况；kernel 会等待数据准备完成，然后将数据拷贝到用户内存；当这一切都完成之后，kernel 会通知用户进程，告诉它 read 操作完成了。

![](/zzimages/20230403201031.png)

## 6.2 I/O软件层次结构

整个I/O软件可以视为具有4个层次的系统结构，自上至下分别是用户层软件、设备独立性软件、设备驱动程序、中断处理程序，再往下一层就是硬件。其中设备独立性软件、设备驱动程序和中断处理程序属于操作系统的内核部分，即I/O系统(或称I/O核心子系统)。

### 1. 用户层软件

用户层软件实现了与用户交互的接口，用户可直接使用该层提供的、与I/O操作相关的库函数对设备进行操作；用户层软件将用户请求翻译成格式化的I/O请求，并通过系统调用请求操作系统内核的服务。

### 2. 设备独立性软件

设备独立性软件又称设备无关性软件，与设备的硬件特性无关的功能几乎都在这一层实现。主要实现的功能为：向上层提供统一的调用接口、执行所有设备的公有操作，包括：
- I/O调度：用某种算法确定一个好的顺序来处理各个I/O请求，如磁盘调度。
- 设备保护：操作系统需要实现文件保护功能，在UNIX系统中设备被看作是一种特殊的文件，每个设备也有对应的FCB，当用户请求访问某个设备时，系统根据FCB中记录的信息来判断该用户是否有相应的访问权限，以此实现设备保护的功能。
- 差错处理
- 设备的分配与回收
- 缓冲区管理
- 建立逻辑设备名到物理设备名的映射关系并根据设备类型选择调用相应的驱动程序(设备独立性软件通过逻辑设备表(LUT)来确定逻辑设备对应的物理设备，并找到该设备对应的设备驱动程序。操作系统可以采用两种方式管理LUT，第一种是整个系统只设置一张LUT，适用于单用户操作系统，第二种是为每个用户设置一张LUT，将其存放在每个用户管理进程的PCB中，适用于多用户操作系统)。
- 假脱机技术(SPOOLing技术)：假脱机技术需要请求磁盘设备的设备独立性软件的服务，因此一般来说假脱机技术是在用户层软件实现的。

### 3. 设备驱动程序

主要负责对硬件设备的具体控制(所有设备交互的细节都封装在设备驱动程序中)，将上层发出的一些列命令转化成特定设备能识别的一系列操作(包括设置设备寄存器，检查设备状态等)。不同的I/O设备有不同的硬件特性，具体细节只有设备的厂家才知道，因此厂家需要根据设备的硬件特性设计并提供相应的驱动程序。驱动程序一般会以一个独立进程的方式存在。

### 4. 中断处理程序

用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完毕再恢复被中断进程的现场后，返回到被中断进程。中断处理程序和设备驱动程序都与硬件紧密相关。

## 6.3 缓冲区管理

缓冲区是一个存储区域，可以由专门的硬件寄存器组成(成本高、容量小)，一般情况下更多的是利用内存作为缓冲区，设备独立性软件的缓冲区管理就是要组织管理好这些缓冲区。缓冲区的作用主要有：缓和CPU与I/O设备之间速度不匹配的矛盾；减少对CPU的中断频率，放宽对CPU中断响应时间的限制；解决数据粒度不匹配的问题(如输出进程每次可以生成一块数据，但I/O设备每次只能输出一个字符)；提高CPU与I/O设备之间的并行性。

### 1. 单缓冲

![](/zzimages/20230403201439.png)

### 2. 双缓冲

![](/zzimages/20230403201503.png)

![](/zzimages/20230403201509.png)

![](/zzimages/20230403201515.png)

![](/zzimages/20230403201522.png)

### 3. 循环缓冲区

![](/zzimages/20230403201540.png)

### 4. 缓冲池

![](/zzimages/20230403201555.png)

- 输入进程请求输入数据时，从空缓冲队列中取出一块作为收容输入数据的工作缓冲区(hin)，冲满数据后将缓冲区挂到输入队列队尾
- 计算进程想要取得一块输入数据时，从输入队列中取得一块冲满输入数据的缓冲区作为提取输入数据的工作缓冲区(sin)，缓冲区读空后挂到空缓冲队列
- 计算进程想要将准备好的数据冲入缓冲区时，从空缓冲队列中取出一块作为收容输出数据的工作缓冲区(hout)，数据冲满后将缓冲区挂到输出队列队尾
- 输出进程请求输出数据时，从输出队列中取得一块冲满输出数据的缓冲区作为提取输出数据的工作缓冲区(sout)，缓冲区读空后挂到空缓冲队列

## 6.4 设备的分配与回收

### 1. 设备分配时应考虑的因素

设备的固有属性：
- 独占设备：一个时段只能分配给一个进程(如打印机)
- 共享设备：可同时分配个多个进程使用(如磁盘)，各进程往往是宏观上同时共享使用设备，而微观上交替使用
- 虚拟设备：采用SPOOLing技术将独占设备改造成虚拟的共享设备，可同时分配给多个进程使用(如采用SPOOLing技术实现的共享打印机)

设备的分配算法

设备分配的安全性

![](/zzimages/20230403201743.png)

### 2. 设备分配方式

静态分配：进程运行前为其分配全部所需资源，运行结束后归还资源。这种方式破坏了"请求和保持"条件，所以不会发生死锁。

动态分配：进程运行过程中动态申请设备资源

### 3. 设备分配的数据结构

![](/zzimages/20230403201840.png)

![](/zzimages/20230403201848.png)

![](/zzimages/20230403201854.png)

![](/zzimages/20230403201901.png)

![](/zzimages/20230403201908.png)

### 4. 设备分配步骤

![](/zzimages/20230403201927.png)

![](/zzimages/20230403201934.png)

![](/zzimages/20230403201941.png)

## 6.5 假脱机技术

为了缓和CPU的高速性与I/O设备低速性之间的矛盾，引入了脱机输入/输出技术，它是操作系统中采用的一项将独占设备改造成共享设备的技术。该技术利用专门的外围控制机，将低速I/O设备上的数据传送到高速磁盘上，或者相反。

![](/zzimages/20230403202013.png)

![](/zzimages/20230403202020.png)

![](/zzimages/20230403202032.png)

![](/zzimages/20230403202039.png)

![](/zzimages/20230403202045.png)

## 6.6 磁盘的管理

![](/zzimages/20230403202137.png)

![](/zzimages/20230403202145.png)

![](/zzimages/20230403202153.png)

![](/zzimages/20230403202202.png)

## 6.7 磁盘调度算法

![](/zzimages/20230403202223.png)

![](/zzimages/20230403202229.png)

![](/zzimages/20230403202237.png)

![](/zzimages/20230403202244.png)

![](/zzimages/20230403202251.png)

![](/zzimages/20230403202259.png)

N步扫描算法：将磁盘请求队列分成长度为N的子队列，按FCFS算法依次处理所有队列，每个队列中采用扫描算法。该算法不会产生磁头粘着现象(磁头可能停留在某处不动的情况，SSTF、SCAN、CSCAN都有可能出现磁头粘着现象)。

FSCAN算法：即双队列扫描算法，把磁盘 I/O 请求分成两个队列，交替使用扫描算法处理一个队列，新生成的磁盘 I/O 请求放入另一队列中，所有的新请求都将被推迟到下一次扫描时处理。FSCAN算法是N步扫描算法的简化，它只将磁盘请求队列分成两个子队列。

SPTF调度算法(最短定位时间优先，Shortest Positioning Time First)：根据旋转与寻道相比的相对时间，选择最短的定位时间。SPTF在操作系统中难以实现，通常在驱动器内部执行，现代磁盘本身具有复杂的内部调度程序，它可以准确地实现SPTF。

注：磁盘调度程序执行时也会执行I/O合并，比如读取块33,8,34，则会将33和34的请求合并为单个两块请求，从而降低开销；除此之外，向磁盘发出I/O之前，系统一般会等待一段时间，看是否有新的请求可能会到达磁盘，从而提高整体效率。